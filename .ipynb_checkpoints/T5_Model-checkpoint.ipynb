{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d904a05b-9a7d-4e55-b5e8-d94f69d0020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "import torchaudio\n",
    "from Cave_model import CAVMAEFTAudio\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import torch.nn.init as init\n",
    "from transformers.modeling_outputs import BaseModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8edd18d-dc26-4abe-bb6e-9dcaef4e75bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sayyss/.conda/envs/LTU-Replication/lib/python3.12/site-packages/transformers/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b696eab-249f-4adc-90e0-b1f92ae530fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb49928-847b-40a5-904e-3ef0234e2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ced9ce-676a-406d-8989-d23d62718c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3343f990-9a17-4126-8fd7-5a0d0eb041a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomT5ForConditionalGeneration(T5ForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.audio_encoder = CAVMAEFTAudio()\n",
    "        self.audio_proj = nn.Sequential(nn.LayerNorm(768, elementwise_affine=False), nn.Linear(768, 1024)) \n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def process_audio(self,audio_input):\n",
    "        \n",
    "        audio_input = self.audio_encoder(audio_input.to(device))  # [B, 512, 768]\n",
    "        audio_input = audio_input.reshape(audio_input.shape[0], 8, 64, audio_input.shape[-1])\n",
    "        audio_input = torch.mean(audio_input, dim=1)  # mean pool over the frequency dimension # [B, 64, 768]\n",
    "        audio_input = torch.nn.functional.avg_pool2d(audio_input, (2, 1)) #[B, 32, 768]\n",
    "        # hard norm to 50\n",
    "        audio_input = audio_input / 50\n",
    "        audio_input = self.audio_proj(audio_input) #[B, 32, 1024]\n",
    "        audio_length = audio_input.shape[1]\n",
    "        audio_embeds = audio_input.to(device) # [B,32,1024]\n",
    "        \n",
    "        return audio_embeds\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        input_ids,\n",
    "        audio_input,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        decoder_attention_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        use_cache=None,\n",
    "        encoder_outputs=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # cut decoder_input_ids if past_key_values is used\n",
    "        if past_key_values is not None:\n",
    "            past_length = past_key_values[0][0].shape[2]\n",
    "\n",
    "            # Some generation methods already pass only the last input ID\n",
    "            if input_ids.shape[1] > past_length:\n",
    "                remove_prefix_length = past_length\n",
    "            else:\n",
    "                # Default to old behavior: keep only final ID\n",
    "                remove_prefix_length = input_ids.shape[1] - 1\n",
    "\n",
    "            input_ids = input_ids[:, remove_prefix_length:]\n",
    "\n",
    "        audio_embeds = self.process_audio(audio_input)\n",
    "        # Combine decoder input embeddings with audio embeddings\n",
    "        decoder_inputs_embeds = self.shared(input_ids)\n",
    "        decoder_inputs_embeds = torch.cat((decoder_inputs_embeds, audio_embeds), dim=1) # [B, seq_length+32, 1024]\n",
    "\n",
    "        return {\n",
    "            \"decoder_inputs_embeds\": decoder_inputs_embeds,\n",
    "            \"audio_input\": audio_input,\n",
    "            \"past_key_values\": past_key_values,\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"decoder_attention_mask\": decoder_attention_mask,\n",
    "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
    "            \"use_cache\": use_cache,\n",
    "        }\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        audio_input = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.FloatTensor], Seq2SeqLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[-100, 0, ...,\n",
    "            config.vocab_size - 1]`. All labels set to `-100` are ignored (masked), the loss is only computed for\n",
    "            labels in `[0, ..., config.vocab_size]`\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "        >>> model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "        >>> # training\n",
    "        >>> input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
    "        >>> labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "        >>> outputs = model(input_ids=input_ids, labels=labels)\n",
    "        >>> loss = outputs.loss\n",
    "        >>> logits = outputs.logits\n",
    "\n",
    "        >>> # inference\n",
    "        >>> input_ids = tokenizer(\n",
    "        ...     \"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    "        ... ).input_ids  # Batch size 1\n",
    "        >>> outputs = model.generate(input_ids)\n",
    "        >>> print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "        >>> # studies have shown that owning a dog is good for you.\n",
    "        ```\"\"\"\n",
    "        \n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
    "        if head_mask is not None and decoder_head_mask is None:\n",
    "            if self.config.num_layers == self.config.num_decoder_layers:\n",
    "                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n",
    "                decoder_head_mask = head_mask\n",
    "\n",
    "        # ******** Custom modifications start *********\n",
    "        # Get audio embeddings\n",
    "        if audio_input == None:\n",
    "            raise ValueError(\"audio input cannot be empty\")\n",
    "\n",
    "        audio_embeds = self.process_audio(audio_input) # [B, 32, 1024]\n",
    "        \n",
    "        \"\"\"\n",
    "        audio_input = self.audio_encoder(audio_input)  # [B, 512, 768]\n",
    "        audio_input = audio_input.reshape(audio_input.shape[0], 8, 64, audio_input.shape[-1])\n",
    "        audio_input = torch.mean(audio_input, dim=1)  # mean pool over the frequency dimension # [B, 64, 768]\n",
    "        audio_input = torch.nn.functional.avg_pool2d(audio_input, (2, 1)) #[B, 32, 768]\n",
    "        # hard norm to 50\n",
    "        audio_input = audio_input / 50\n",
    "        audio_input = self.audio_proj(audio_input) #[B, 32, 1024]\n",
    "        audio_length = audio_input.shape[1]\n",
    "        audio_embeds = audio_input.to(device) # [B,32,1024] \n",
    "        \"\"\"\n",
    "        # Custom: get embeddings\n",
    "        # Only runs during training\n",
    "        if inputs_embeds is None and decoder_input_ids is None and input_ids is not None:\n",
    "            \n",
    "            inputs_embeds = self.shared(input_ids).to(device) # [b, seq_length, 768]\n",
    "            inputs_embeds = torch.cat((inputs_embeds, audio_embeds), dim=1)  # Shape: (b,sequence_length + 32, 1024)\n",
    "\n",
    "            max_length = 512\n",
    "            seq_length = inputs_embeds.size(1)\n",
    "            \n",
    "            # Truncate if the sequence length exceeds max_length\n",
    "            if seq_length > max_length:\n",
    "                inputs_embeds = inputs_embeds[:, :max_length, :]\n",
    "                seq_length = max_length\n",
    "            \n",
    "            # Apply padding if the sequence is shorter than max_length\n",
    "            padding_length = max_length - seq_length\n",
    "            if padding_length > 0:\n",
    "                padding_tensor = torch.zeros((inputs_embeds.size(0), padding_length, inputs_embeds.size(2))).to(device)\n",
    "                inputs_embeds = torch.cat((inputs_embeds, padding_tensor), dim=1)\n",
    "            \n",
    "            # Create attention mask\n",
    "            attention_mask = torch.ones((inputs_embeds.size(0), max_length)).to(device)\n",
    "            if padding_length > 0:\n",
    "                attention_mask[:, seq_length:] = 0\n",
    "            \n",
    "            \n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            # Convert encoder inputs in embeddings if needed\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=None, # Custom: change to none because we already defined embeddings\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
    "            encoder_outputs = BaseModelOutput(\n",
    "                last_hidden_state=encoder_outputs[0],\n",
    "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "            )\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "            hidden_states = hidden_states.to(self.decoder.first_device)\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(self.decoder.first_device)\n",
    "            if decoder_attention_mask is not None:\n",
    "                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n",
    "\n",
    "        # modifications for inference\n",
    "        # only runs when inference, skips to using labels as decoder input when training instead\n",
    "        if decoder_inputs_embeds is not None:\n",
    "            decoder_input_ids = None\n",
    "            \n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.encoder.first_device)\n",
    "            self.lm_head = self.lm_head.to(self.encoder.first_device)\n",
    "            sequence_output = sequence_output.to(self.lm_head.weight.device)\n",
    "\n",
    "        if self.config.tie_word_embeddings:\n",
    "            # Rescale output before projecting on vocab\n",
    "            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "            sequence_output = sequence_output * (self.model_dim**-0.5)\n",
    "\n",
    "        lm_logits = self.lm_head(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
    "            # move labels to correct device to enable PP\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f59470-b3b8-4e11-87e5-2c5291e33ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayyss/.conda/envs/LTU-Replication/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of CustomT5ForConditionalGeneration were not initialized from the model checkpoint at MBZUAI/LaMini-T5-738M and are newly initialized: ['audio_encoder.blocks_a.0.attn.proj.bias', 'audio_encoder.blocks_a.0.attn.proj.weight', 'audio_encoder.blocks_a.0.attn.qkv.bias', 'audio_encoder.blocks_a.0.attn.qkv.weight', 'audio_encoder.blocks_a.0.mlp.fc1.bias', 'audio_encoder.blocks_a.0.mlp.fc1.weight', 'audio_encoder.blocks_a.0.mlp.fc2.bias', 'audio_encoder.blocks_a.0.mlp.fc2.weight', 'audio_encoder.blocks_a.0.norm1.bias', 'audio_encoder.blocks_a.0.norm1.weight', 'audio_encoder.blocks_a.0.norm1_a.bias', 'audio_encoder.blocks_a.0.norm1_a.weight', 'audio_encoder.blocks_a.0.norm1_v.bias', 'audio_encoder.blocks_a.0.norm1_v.weight', 'audio_encoder.blocks_a.0.norm2.bias', 'audio_encoder.blocks_a.0.norm2.weight', 'audio_encoder.blocks_a.0.norm2_a.bias', 'audio_encoder.blocks_a.0.norm2_a.weight', 'audio_encoder.blocks_a.0.norm2_v.bias', 'audio_encoder.blocks_a.0.norm2_v.weight', 'audio_encoder.blocks_a.1.attn.proj.bias', 'audio_encoder.blocks_a.1.attn.proj.weight', 'audio_encoder.blocks_a.1.attn.qkv.bias', 'audio_encoder.blocks_a.1.attn.qkv.weight', 'audio_encoder.blocks_a.1.mlp.fc1.bias', 'audio_encoder.blocks_a.1.mlp.fc1.weight', 'audio_encoder.blocks_a.1.mlp.fc2.bias', 'audio_encoder.blocks_a.1.mlp.fc2.weight', 'audio_encoder.blocks_a.1.norm1.bias', 'audio_encoder.blocks_a.1.norm1.weight', 'audio_encoder.blocks_a.1.norm1_a.bias', 'audio_encoder.blocks_a.1.norm1_a.weight', 'audio_encoder.blocks_a.1.norm1_v.bias', 'audio_encoder.blocks_a.1.norm1_v.weight', 'audio_encoder.blocks_a.1.norm2.bias', 'audio_encoder.blocks_a.1.norm2.weight', 'audio_encoder.blocks_a.1.norm2_a.bias', 'audio_encoder.blocks_a.1.norm2_a.weight', 'audio_encoder.blocks_a.1.norm2_v.bias', 'audio_encoder.blocks_a.1.norm2_v.weight', 'audio_encoder.blocks_a.10.attn.proj.bias', 'audio_encoder.blocks_a.10.attn.proj.weight', 'audio_encoder.blocks_a.10.attn.qkv.bias', 'audio_encoder.blocks_a.10.attn.qkv.weight', 'audio_encoder.blocks_a.10.mlp.fc1.bias', 'audio_encoder.blocks_a.10.mlp.fc1.weight', 'audio_encoder.blocks_a.10.mlp.fc2.bias', 'audio_encoder.blocks_a.10.mlp.fc2.weight', 'audio_encoder.blocks_a.10.norm1.bias', 'audio_encoder.blocks_a.10.norm1.weight', 'audio_encoder.blocks_a.10.norm1_a.bias', 'audio_encoder.blocks_a.10.norm1_a.weight', 'audio_encoder.blocks_a.10.norm1_v.bias', 'audio_encoder.blocks_a.10.norm1_v.weight', 'audio_encoder.blocks_a.10.norm2.bias', 'audio_encoder.blocks_a.10.norm2.weight', 'audio_encoder.blocks_a.10.norm2_a.bias', 'audio_encoder.blocks_a.10.norm2_a.weight', 'audio_encoder.blocks_a.10.norm2_v.bias', 'audio_encoder.blocks_a.10.norm2_v.weight', 'audio_encoder.blocks_a.2.attn.proj.bias', 'audio_encoder.blocks_a.2.attn.proj.weight', 'audio_encoder.blocks_a.2.attn.qkv.bias', 'audio_encoder.blocks_a.2.attn.qkv.weight', 'audio_encoder.blocks_a.2.mlp.fc1.bias', 'audio_encoder.blocks_a.2.mlp.fc1.weight', 'audio_encoder.blocks_a.2.mlp.fc2.bias', 'audio_encoder.blocks_a.2.mlp.fc2.weight', 'audio_encoder.blocks_a.2.norm1.bias', 'audio_encoder.blocks_a.2.norm1.weight', 'audio_encoder.blocks_a.2.norm1_a.bias', 'audio_encoder.blocks_a.2.norm1_a.weight', 'audio_encoder.blocks_a.2.norm1_v.bias', 'audio_encoder.blocks_a.2.norm1_v.weight', 'audio_encoder.blocks_a.2.norm2.bias', 'audio_encoder.blocks_a.2.norm2.weight', 'audio_encoder.blocks_a.2.norm2_a.bias', 'audio_encoder.blocks_a.2.norm2_a.weight', 'audio_encoder.blocks_a.2.norm2_v.bias', 'audio_encoder.blocks_a.2.norm2_v.weight', 'audio_encoder.blocks_a.3.attn.proj.bias', 'audio_encoder.blocks_a.3.attn.proj.weight', 'audio_encoder.blocks_a.3.attn.qkv.bias', 'audio_encoder.blocks_a.3.attn.qkv.weight', 'audio_encoder.blocks_a.3.mlp.fc1.bias', 'audio_encoder.blocks_a.3.mlp.fc1.weight', 'audio_encoder.blocks_a.3.mlp.fc2.bias', 'audio_encoder.blocks_a.3.mlp.fc2.weight', 'audio_encoder.blocks_a.3.norm1.bias', 'audio_encoder.blocks_a.3.norm1.weight', 'audio_encoder.blocks_a.3.norm1_a.bias', 'audio_encoder.blocks_a.3.norm1_a.weight', 'audio_encoder.blocks_a.3.norm1_v.bias', 'audio_encoder.blocks_a.3.norm1_v.weight', 'audio_encoder.blocks_a.3.norm2.bias', 'audio_encoder.blocks_a.3.norm2.weight', 'audio_encoder.blocks_a.3.norm2_a.bias', 'audio_encoder.blocks_a.3.norm2_a.weight', 'audio_encoder.blocks_a.3.norm2_v.bias', 'audio_encoder.blocks_a.3.norm2_v.weight', 'audio_encoder.blocks_a.4.attn.proj.bias', 'audio_encoder.blocks_a.4.attn.proj.weight', 'audio_encoder.blocks_a.4.attn.qkv.bias', 'audio_encoder.blocks_a.4.attn.qkv.weight', 'audio_encoder.blocks_a.4.mlp.fc1.bias', 'audio_encoder.blocks_a.4.mlp.fc1.weight', 'audio_encoder.blocks_a.4.mlp.fc2.bias', 'audio_encoder.blocks_a.4.mlp.fc2.weight', 'audio_encoder.blocks_a.4.norm1.bias', 'audio_encoder.blocks_a.4.norm1.weight', 'audio_encoder.blocks_a.4.norm1_a.bias', 'audio_encoder.blocks_a.4.norm1_a.weight', 'audio_encoder.blocks_a.4.norm1_v.bias', 'audio_encoder.blocks_a.4.norm1_v.weight', 'audio_encoder.blocks_a.4.norm2.bias', 'audio_encoder.blocks_a.4.norm2.weight', 'audio_encoder.blocks_a.4.norm2_a.bias', 'audio_encoder.blocks_a.4.norm2_a.weight', 'audio_encoder.blocks_a.4.norm2_v.bias', 'audio_encoder.blocks_a.4.norm2_v.weight', 'audio_encoder.blocks_a.5.attn.proj.bias', 'audio_encoder.blocks_a.5.attn.proj.weight', 'audio_encoder.blocks_a.5.attn.qkv.bias', 'audio_encoder.blocks_a.5.attn.qkv.weight', 'audio_encoder.blocks_a.5.mlp.fc1.bias', 'audio_encoder.blocks_a.5.mlp.fc1.weight', 'audio_encoder.blocks_a.5.mlp.fc2.bias', 'audio_encoder.blocks_a.5.mlp.fc2.weight', 'audio_encoder.blocks_a.5.norm1.bias', 'audio_encoder.blocks_a.5.norm1.weight', 'audio_encoder.blocks_a.5.norm1_a.bias', 'audio_encoder.blocks_a.5.norm1_a.weight', 'audio_encoder.blocks_a.5.norm1_v.bias', 'audio_encoder.blocks_a.5.norm1_v.weight', 'audio_encoder.blocks_a.5.norm2.bias', 'audio_encoder.blocks_a.5.norm2.weight', 'audio_encoder.blocks_a.5.norm2_a.bias', 'audio_encoder.blocks_a.5.norm2_a.weight', 'audio_encoder.blocks_a.5.norm2_v.bias', 'audio_encoder.blocks_a.5.norm2_v.weight', 'audio_encoder.blocks_a.6.attn.proj.bias', 'audio_encoder.blocks_a.6.attn.proj.weight', 'audio_encoder.blocks_a.6.attn.qkv.bias', 'audio_encoder.blocks_a.6.attn.qkv.weight', 'audio_encoder.blocks_a.6.mlp.fc1.bias', 'audio_encoder.blocks_a.6.mlp.fc1.weight', 'audio_encoder.blocks_a.6.mlp.fc2.bias', 'audio_encoder.blocks_a.6.mlp.fc2.weight', 'audio_encoder.blocks_a.6.norm1.bias', 'audio_encoder.blocks_a.6.norm1.weight', 'audio_encoder.blocks_a.6.norm1_a.bias', 'audio_encoder.blocks_a.6.norm1_a.weight', 'audio_encoder.blocks_a.6.norm1_v.bias', 'audio_encoder.blocks_a.6.norm1_v.weight', 'audio_encoder.blocks_a.6.norm2.bias', 'audio_encoder.blocks_a.6.norm2.weight', 'audio_encoder.blocks_a.6.norm2_a.bias', 'audio_encoder.blocks_a.6.norm2_a.weight', 'audio_encoder.blocks_a.6.norm2_v.bias', 'audio_encoder.blocks_a.6.norm2_v.weight', 'audio_encoder.blocks_a.7.attn.proj.bias', 'audio_encoder.blocks_a.7.attn.proj.weight', 'audio_encoder.blocks_a.7.attn.qkv.bias', 'audio_encoder.blocks_a.7.attn.qkv.weight', 'audio_encoder.blocks_a.7.mlp.fc1.bias', 'audio_encoder.blocks_a.7.mlp.fc1.weight', 'audio_encoder.blocks_a.7.mlp.fc2.bias', 'audio_encoder.blocks_a.7.mlp.fc2.weight', 'audio_encoder.blocks_a.7.norm1.bias', 'audio_encoder.blocks_a.7.norm1.weight', 'audio_encoder.blocks_a.7.norm1_a.bias', 'audio_encoder.blocks_a.7.norm1_a.weight', 'audio_encoder.blocks_a.7.norm1_v.bias', 'audio_encoder.blocks_a.7.norm1_v.weight', 'audio_encoder.blocks_a.7.norm2.bias', 'audio_encoder.blocks_a.7.norm2.weight', 'audio_encoder.blocks_a.7.norm2_a.bias', 'audio_encoder.blocks_a.7.norm2_a.weight', 'audio_encoder.blocks_a.7.norm2_v.bias', 'audio_encoder.blocks_a.7.norm2_v.weight', 'audio_encoder.blocks_a.8.attn.proj.bias', 'audio_encoder.blocks_a.8.attn.proj.weight', 'audio_encoder.blocks_a.8.attn.qkv.bias', 'audio_encoder.blocks_a.8.attn.qkv.weight', 'audio_encoder.blocks_a.8.mlp.fc1.bias', 'audio_encoder.blocks_a.8.mlp.fc1.weight', 'audio_encoder.blocks_a.8.mlp.fc2.bias', 'audio_encoder.blocks_a.8.mlp.fc2.weight', 'audio_encoder.blocks_a.8.norm1.bias', 'audio_encoder.blocks_a.8.norm1.weight', 'audio_encoder.blocks_a.8.norm1_a.bias', 'audio_encoder.blocks_a.8.norm1_a.weight', 'audio_encoder.blocks_a.8.norm1_v.bias', 'audio_encoder.blocks_a.8.norm1_v.weight', 'audio_encoder.blocks_a.8.norm2.bias', 'audio_encoder.blocks_a.8.norm2.weight', 'audio_encoder.blocks_a.8.norm2_a.bias', 'audio_encoder.blocks_a.8.norm2_a.weight', 'audio_encoder.blocks_a.8.norm2_v.bias', 'audio_encoder.blocks_a.8.norm2_v.weight', 'audio_encoder.blocks_a.9.attn.proj.bias', 'audio_encoder.blocks_a.9.attn.proj.weight', 'audio_encoder.blocks_a.9.attn.qkv.bias', 'audio_encoder.blocks_a.9.attn.qkv.weight', 'audio_encoder.blocks_a.9.mlp.fc1.bias', 'audio_encoder.blocks_a.9.mlp.fc1.weight', 'audio_encoder.blocks_a.9.mlp.fc2.bias', 'audio_encoder.blocks_a.9.mlp.fc2.weight', 'audio_encoder.blocks_a.9.norm1.bias', 'audio_encoder.blocks_a.9.norm1.weight', 'audio_encoder.blocks_a.9.norm1_a.bias', 'audio_encoder.blocks_a.9.norm1_a.weight', 'audio_encoder.blocks_a.9.norm1_v.bias', 'audio_encoder.blocks_a.9.norm1_v.weight', 'audio_encoder.blocks_a.9.norm2.bias', 'audio_encoder.blocks_a.9.norm2.weight', 'audio_encoder.blocks_a.9.norm2_a.bias', 'audio_encoder.blocks_a.9.norm2_a.weight', 'audio_encoder.blocks_a.9.norm2_v.bias', 'audio_encoder.blocks_a.9.norm2_v.weight', 'audio_encoder.blocks_u.0.attn.proj.bias', 'audio_encoder.blocks_u.0.attn.proj.weight', 'audio_encoder.blocks_u.0.attn.qkv.bias', 'audio_encoder.blocks_u.0.attn.qkv.weight', 'audio_encoder.blocks_u.0.mlp.fc1.bias', 'audio_encoder.blocks_u.0.mlp.fc1.weight', 'audio_encoder.blocks_u.0.mlp.fc2.bias', 'audio_encoder.blocks_u.0.mlp.fc2.weight', 'audio_encoder.blocks_u.0.norm1.bias', 'audio_encoder.blocks_u.0.norm1.weight', 'audio_encoder.blocks_u.0.norm1_a.bias', 'audio_encoder.blocks_u.0.norm1_a.weight', 'audio_encoder.blocks_u.0.norm1_v.bias', 'audio_encoder.blocks_u.0.norm1_v.weight', 'audio_encoder.blocks_u.0.norm2.bias', 'audio_encoder.blocks_u.0.norm2.weight', 'audio_encoder.blocks_u.0.norm2_a.bias', 'audio_encoder.blocks_u.0.norm2_a.weight', 'audio_encoder.blocks_u.0.norm2_v.bias', 'audio_encoder.blocks_u.0.norm2_v.weight', 'audio_encoder.modality_a', 'audio_encoder.norm_a.bias', 'audio_encoder.norm_a.weight', 'audio_encoder.patch_embed_a.proj.bias', 'audio_encoder.patch_embed_a.proj.weight', 'audio_encoder.pos_embed_a', 'audio_proj.1.bias', 'audio_proj.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and config\n",
    "#tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "config = T5Config.from_pretrained(\"MBZUAI/LaMini-T5-738M\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"MBZUAI/LaMini-T5-738M\")\n",
    "\n",
    "# Initialize your custom model\n",
    "customT5 = CustomT5ForConditionalGeneration(config)\n",
    "#model = customT5.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\\\n",
    "model = customT5.from_pretrained(\"MBZUAI/LaMini-T5-738M\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a941a9-fc97-48bc-9a1a-e51bdf931278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.post_init()\n",
    "model.audio_encoder.initialize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cebe8f0d-b587-4471-b67f-3bfd5405b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.audio_proj[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "949d95ef-f972-48b1-be03-7d67a4164f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def get_methods_and_params(cls):\n",
    "    methods_and_params = []\n",
    "    for name, member in inspect.getmembers(cls):\n",
    "        if inspect.ismethod(member) or inspect.isfunction(member):\n",
    "            parameters = inspect.signature(member).parameters\n",
    "            param_names = [param for param in parameters.keys() if param != 'self']\n",
    "            methods_and_params.append((name, tuple(param_names)))\n",
    "    return methods_and_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60da6ba5-44dc-437c-9282-a944b0536f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824176640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2146e1-efdc-48a7-a084-09b3d379b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./data/toy_dataset/openaqa_toy.json\"\n",
    "\n",
    "with open(file, \"r\") as jsonFile:\n",
    "    data = json.load(jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c435d-eafe-4f64-9f28-6dd0e5c8f16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d9065-5f15-4d5a-8178-9dd6d3f4b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4e5abb-b769-4452-aeb9-804142cc8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    path = data[i]['audio_id']\n",
    "    exten = path[len(path)-4:]\n",
    "    if exten == \"flac\" or exten == \".wav\":\n",
    "        mini_path = \"\"\n",
    "        for j in range(len(path)-1, -1, -1):\n",
    "            if path[j] == \"/\":\n",
    "                break\n",
    "            mini_path += path[j]\n",
    "        data[i]['audio_id'] = \"./data/toy_dataset/audio/\" + mini_path[::-1]\n",
    "        \n",
    "with open(file, \"w\") as jsonFile:\n",
    "    json.dump(data, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67caa384-5ded-4ca9-a2bf-23e36042eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"json\", data_files=file, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "035c3b52-b557-4d9a-88b5-720125da5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ebd258-ca28-4e60-8659-e1d12fd45e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5044, 6), (1262, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e372e9f-e83f-4fe4-9279-8f2d35089138",
   "metadata": {},
   "source": [
    "### Only train on classifying audio first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039bef0a-76ac-412a-9ee3-31bc437727d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(train_dataset.shape[0]):\n",
    "    if train_dataset[i]['task'].startswith(\"cla\"):\n",
    "        #print(train_dataset[i])\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b50ad169-60a7-4f59-9aea-e9fc71a19d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27882b349c945fc999fef3c9abf2b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5044 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37d0cc8b82e4bb691cef7a9690da5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def is_classification_task(input):\n",
    "    return input['task'].startswith(\"cla\")\n",
    "\n",
    "train_cla_dataset = train_dataset.filter(is_classification_task)\n",
    "test_cla_dataset = test_dataset.filter(is_classification_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41f37cf-0be8-41e3-9fe3-33fd19e10d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1099, 6), (296, 6))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cla_dataset.shape, test_cla_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06359c06-29b2-4c0b-b7c8-8843dc58e174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Closed-ended question: Perform audio event classification on audio clip, produce tags solely for audio.',\n",
       " 'input': '',\n",
       " 'audio_id': './data/toy_dataset/audio/rKJYI_rn_sg_000001.flac',\n",
       " 'dataset': 'vggsound_train',\n",
       " 'task': 'cla_label',\n",
       " 'output': 'Labels: Gibbon howling'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cla_dataset[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c4c270-b7fc-4f13-a362-84f0e23ee5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filterbank\n",
    "def load_audio(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    audio_info = 'Original input audio length {:.2f} seconds, number of channels: {:d}, sampling rate: {:d}.'.format(waveform.shape[1]/sample_rate, waveform.shape[0], sample_rate)\n",
    "    if waveform.shape[0] != 1:\n",
    "        waveform = waveform[0].unsqueeze(0)\n",
    "        audio_info += ' Only the first channel is used.'\n",
    "    if sample_rate == 16000:\n",
    "        pass\n",
    "    else:\n",
    "        waveform = torchaudio.functional.resample(waveform, orig_freq=sample_rate, new_freq=16000)\n",
    "        sample_rate = 16000\n",
    "        audio_info += ' Resample to 16000Hz.'\n",
    "    waveform = waveform - waveform.mean()\n",
    "    fbank = torchaudio.compliance.kaldi.fbank(waveform, htk_compat=True, sample_frequency=sample_rate,\n",
    "                                              use_energy=False, window_type='hanning',\n",
    "                                              num_mel_bins=128, dither=0.0, frame_shift=10)\n",
    "    target_length = 1024\n",
    "    n_frames = fbank.shape[0]\n",
    "    p = target_length - n_frames\n",
    "    if p > 0:\n",
    "        m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "        fbank = m(fbank)\n",
    "    elif p < 0:\n",
    "        fbank = fbank[0:target_length, :]\n",
    "    # normalize the fbank\n",
    "    fbank = (fbank + 5.081) / 4.4849\n",
    "    return fbank, audio_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "726a253e-ba72-41a3-94d3-e46f95459c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def return_audio(path):\n",
    "\n",
    "    cur_audio_input, audio_info = load_audio(path)\n",
    "    cur_audio_input = cur_audio_input.unsqueeze(0)\n",
    "    \n",
    "    # projecting to 1024 input embedding dimension for T5\n",
    "    audio_proj = nn.Sequential(nn.LayerNorm(768, elementwise_affine=False), nn.Linear(768, 1024))\n",
    "    audio_input = audio_encoder(cur_audio_input)  # [B, 512, 768]\n",
    "    audio_input = audio_input.reshape(audio_input.shape[0], 8, 64, audio_input.shape[-1])\n",
    "    audio_input = torch.mean(audio_input, dim=1)  # mean pool over the frequency dimension # [B, 64, 768]\n",
    "    audio_input = torch.nn.functional.avg_pool2d(audio_input, (2, 1)) #[B, 32, 768]\n",
    "    # hard norm to 50\n",
    "    audio_input = audio_input / 50\n",
    "    audio_input = audio_proj(audio_input) #[B, 32, 1024]\n",
    "    \n",
    "    return audio_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c664636-70a2-44d0-9451-b6a8c321ecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abfcde6e-8a70-4175-8b7e-3fe3c7149121",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3568881c-033a-4f25-b638-55d269fcbf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42670ff5-a524-4846-9f6b-c93b944ed181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class CombinedEmbeddingsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, model, device, max_length=512):\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        instruction = self.data[idx]['instruction']\n",
    "        audio_path = self.data[idx]['audio_id']\n",
    "        label = self.data[idx]['output']\n",
    "        \n",
    "        input_ids = self.tokenizer(instruction, return_tensors=\"pt\").input_ids.to(self.device)\n",
    "        decoder_input_ids = self.tokenizer(label, return_tensors=\"pt\").input_ids.to(self.device)\n",
    "        audio_bank, audio_info = load_audio(audio_path)\n",
    "        audio_bank = audio_bank.to(self.device)\n",
    "        \n",
    "        return input_ids, decoder_input_ids.squeeze(0), audio_bank\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    input_ids = [item[0].squeeze(0) for item in batch]  # Remove unnecessary dim\n",
    "    decoder_input_ids = [item[1] for item in batch]\n",
    "    audio_input = [item[2] for item in batch]\n",
    "\n",
    "    # Pad input_ids and decoder_input_ids to the maximum length in the batch\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    decoder_input_ids_padded = pad_sequence(decoder_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    \n",
    "    # Stack audio inputs directly if they have the same size\n",
    "    audio_input_stacked = torch.stack(audio_input)\n",
    "    return input_ids_padded, audio_input_stacked, decoder_input_ids_padded\n",
    "\n",
    "\n",
    "#dataset = CombinedEmbeddingsDataset(train_dataset, tokenizer, model, device)\n",
    "#dataloader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8002bb8e-8eb6-4621-aac4-c0045a50306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CombinedEmbeddingsDataset(train_cla_dataset, tokenizer, model, device)\n",
    "dataloader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d6e7478-a346-430f-b431-1ad6ece42a45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/LTU-Replication/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/LTU-Replication/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/LTU-Replication/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, (input_ids, audio_bank, decoder_input_ids) in enumerate(dataloader):\n",
    "        if torch.isnan(input_ids).any() or torch.isnan(audio_bank).any() or torch.isnan(decoder_input_ids).any():\n",
    "            print(\"NaN detected in input tensors\")\n",
    "            continue\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, audio_input=audio_bank, labels=decoder_input_ids)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / 10\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d775a-ca1e-4747-a906-56c95e27235e",
   "metadata": {},
   "source": [
    "#### Freeze Audio encoder and LLM, only train projection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "213cefaf-6784-4d61-b166-898c8ce912ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 644.1280\n",
      "Epoch 2/5, Average Loss: 644.1280\n",
      "Epoch 3/5, Average Loss: 644.1280\n",
      "Epoch 4/5, Average Loss: 644.1280\n",
      "Epoch 5/5, Average Loss: 644.1280\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.audio_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.audio_proj.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.audio_proj.parameters(), lr=1e-6)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (input_ids, audio_bank, decoder_input_ids) in enumerate(dataloader):\n",
    "        if torch.isnan(input_ids).any() or torch.isnan(audio_bank).any() or torch.isnan(decoder_input_ids).any():\n",
    "            print(\"NaN detected in input tensors\")\n",
    "            continue\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, audio_input=audio_bank, labels=decoder_input_ids)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / 10\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b4ebe8-5573-455b-8fe1-c888b007921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': num_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"working_model_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c34993b-8ea6-4622-8894-f5d937fb29e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factura factura factura factura factura factura factura factura factura factura factura factura factura factura factura factura factura factura factura\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/toy_dataset/audio/74S7Gw80ZOo_000040.flac\"\n",
    "cur_audio_input, audio_info = load_audio(file)\n",
    "cur_audio_input = cur_audio_input.unsqueeze(0).to(device)\n",
    "prompt_text = \"This clip contains these sounds? Generate audio labels instantly:\"\n",
    "input_ids = tokenizer(prompt_text, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=input_ids, audio_input=cur_audio_input)\n",
    "    \n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c646d306-1ba5-4967-8e3d-91d77328ad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 27188, 27188, 27188, 27188, 27188, 27188, 27188, 27188, 27188,\n",
       "         27188, 27188, 27188, 27188, 27188, 27188, 27188, 27188, 27188, 27188]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32cfd7a6-78ed-4d1d-b4ea-52115a298760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "shared.weight : tensor(-0.1905, device='cuda:0') tensor(9.9409, device='cuda:0')\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight : tensor(7.0893e-06, device='cuda:0') tensor(0.0321, device='cuda:0')\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight : tensor(0.0006, device='cuda:0') tensor(0.2651, device='cuda:0')\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.1377, device='cuda:0')\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight : tensor(0.0006, device='cuda:0') tensor(0.2651, device='cuda:0')\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight : tensor(2.3460, device='cuda:0') tensor(4.1137, device='cuda:0')\n",
      "encoder.block.0.layer.0.layer_norm.weight : tensor(0.1013, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0036, device='cuda:0') tensor(0.2012, device='cuda:0')\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.1830, device='cuda:0')\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.1724, device='cuda:0')\n",
      "encoder.block.0.layer.1.layer_norm.weight : tensor(0.1050, device='cuda:0') tensor(0.0464, device='cuda:0')\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight : tensor(-4.0891e-05, device='cuda:0') tensor(0.0430, device='cuda:0')\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight : tensor(0.0004, device='cuda:0') tensor(0.2974, device='cuda:0')\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight : tensor(6.2364e-05, device='cuda:0') tensor(0.0818, device='cuda:0')\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight : tensor(0.0002, device='cuda:0') tensor(0.2057, device='cuda:0')\n",
      "encoder.block.1.layer.0.layer_norm.weight : tensor(0.1922, device='cuda:0') tensor(0.0885, device='cuda:0')\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0004, device='cuda:0') tensor(0.2435, device='cuda:0')\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0006, device='cuda:0') tensor(0.1936, device='cuda:0')\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.2088, device='cuda:0')\n",
      "encoder.block.1.layer.1.layer_norm.weight : tensor(0.1261, device='cuda:0') tensor(0.0746, device='cuda:0')\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight : tensor(-1.2473e-05, device='cuda:0') tensor(0.0369, device='cuda:0')\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.2879, device='cuda:0')\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight : tensor(2.8419e-05, device='cuda:0') tensor(0.1277, device='cuda:0')\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.2869, device='cuda:0')\n",
      "encoder.block.2.layer.0.layer_norm.weight : tensor(0.1549, device='cuda:0') tensor(0.0878, device='cuda:0')\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0016, device='cuda:0') tensor(0.2666, device='cuda:0')\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0004, device='cuda:0') tensor(0.2358, device='cuda:0')\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.2391, device='cuda:0')\n",
      "encoder.block.2.layer.1.layer_norm.weight : tensor(0.1349, device='cuda:0') tensor(0.0832, device='cuda:0')\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight : tensor(-5.7082e-05, device='cuda:0') tensor(0.0391, device='cuda:0')\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight : tensor(-0.0005, device='cuda:0') tensor(0.2995, device='cuda:0')\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight : tensor(9.0121e-05, device='cuda:0') tensor(0.1389, device='cuda:0')\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.2796, device='cuda:0')\n",
      "encoder.block.3.layer.0.layer_norm.weight : tensor(0.1761, device='cuda:0') tensor(0.1000, device='cuda:0')\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0028, device='cuda:0') tensor(0.2807, device='cuda:0')\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.2627, device='cuda:0')\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight : tensor(-0.0005, device='cuda:0') tensor(0.2495, device='cuda:0')\n",
      "encoder.block.3.layer.1.layer_norm.weight : tensor(0.1440, device='cuda:0') tensor(0.0825, device='cuda:0')\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight : tensor(7.9562e-05, device='cuda:0') tensor(0.0398, device='cuda:0')\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight : tensor(-0.0005, device='cuda:0') tensor(0.3064, device='cuda:0')\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight : tensor(0.0003, device='cuda:0') tensor(0.1451, device='cuda:0')\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.2783, device='cuda:0')\n",
      "encoder.block.4.layer.0.layer_norm.weight : tensor(0.1823, device='cuda:0') tensor(0.0987, device='cuda:0')\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0031, device='cuda:0') tensor(0.2855, device='cuda:0')\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0009, device='cuda:0') tensor(0.2943, device='cuda:0')\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight : tensor(-0.0005, device='cuda:0') tensor(0.2354, device='cuda:0')\n",
      "encoder.block.4.layer.1.layer_norm.weight : tensor(0.1568, device='cuda:0') tensor(0.0905, device='cuda:0')\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight : tensor(-2.3038e-05, device='cuda:0') tensor(0.0373, device='cuda:0')\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight : tensor(0.0004, device='cuda:0') tensor(0.2827, device='cuda:0')\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight : tensor(2.0816e-05, device='cuda:0') tensor(0.1663, device='cuda:0')\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight : tensor(-0.0001, device='cuda:0') tensor(0.2945, device='cuda:0')\n",
      "encoder.block.5.layer.0.layer_norm.weight : tensor(0.2070, device='cuda:0') tensor(0.1144, device='cuda:0')\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0040, device='cuda:0') tensor(0.3014, device='cuda:0')\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0009, device='cuda:0') tensor(0.3285, device='cuda:0')\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.2470, device='cuda:0')\n",
      "encoder.block.5.layer.1.layer_norm.weight : tensor(0.1541, device='cuda:0') tensor(0.0776, device='cuda:0')\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight : tensor(6.8996e-05, device='cuda:0') tensor(0.0408, device='cuda:0')\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight : tensor(-5.9658e-05, device='cuda:0') tensor(0.3083, device='cuda:0')\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.1758, device='cuda:0')\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.2965, device='cuda:0')\n",
      "encoder.block.6.layer.0.layer_norm.weight : tensor(0.1879, device='cuda:0') tensor(0.0986, device='cuda:0')\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0045, device='cuda:0') tensor(0.3003, device='cuda:0')\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.3516, device='cuda:0')\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.2428, device='cuda:0')\n",
      "encoder.block.6.layer.1.layer_norm.weight : tensor(0.1625, device='cuda:0') tensor(0.0756, device='cuda:0')\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight : tensor(-9.1128e-05, device='cuda:0') tensor(0.0418, device='cuda:0')\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight : tensor(-0.0005, device='cuda:0') tensor(0.3194, device='cuda:0')\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight : tensor(0.0002, device='cuda:0') tensor(0.1975, device='cuda:0')\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.3119, device='cuda:0')\n",
      "encoder.block.7.layer.0.layer_norm.weight : tensor(0.2014, device='cuda:0') tensor(0.1027, device='cuda:0')\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0056, device='cuda:0') tensor(0.3016, device='cuda:0')\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.3697, device='cuda:0')\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.2561, device='cuda:0')\n",
      "encoder.block.7.layer.1.layer_norm.weight : tensor(0.1694, device='cuda:0') tensor(0.0739, device='cuda:0')\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight : tensor(2.9124e-05, device='cuda:0') tensor(0.0407, device='cuda:0')\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight : tensor(0.0003, device='cuda:0') tensor(0.3135, device='cuda:0')\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.2076, device='cuda:0')\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight : tensor(0.0001, device='cuda:0') tensor(0.3185, device='cuda:0')\n",
      "encoder.block.8.layer.0.layer_norm.weight : tensor(0.2025, device='cuda:0') tensor(0.0964, device='cuda:0')\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0060, device='cuda:0') tensor(0.3043, device='cuda:0')\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.3874, device='cuda:0')\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.2784, device='cuda:0')\n",
      "encoder.block.8.layer.1.layer_norm.weight : tensor(0.1660, device='cuda:0') tensor(0.0683, device='cuda:0')\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight : tensor(0.0001, device='cuda:0') tensor(0.0418, device='cuda:0')\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.3329, device='cuda:0')\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight : tensor(7.7767e-05, device='cuda:0') tensor(0.2192, device='cuda:0')\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight : tensor(-0.0001, device='cuda:0') tensor(0.3108, device='cuda:0')\n",
      "encoder.block.9.layer.0.layer_norm.weight : tensor(0.2072, device='cuda:0') tensor(0.0951, device='cuda:0')\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0057, device='cuda:0') tensor(0.2982, device='cuda:0')\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0009, device='cuda:0') tensor(0.4123, device='cuda:0')\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.2837, device='cuda:0')\n",
      "encoder.block.9.layer.1.layer_norm.weight : tensor(0.1660, device='cuda:0') tensor(0.0636, device='cuda:0')\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight : tensor(8.5378e-06, device='cuda:0') tensor(0.0395, device='cuda:0')\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.3160, device='cuda:0')\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.2403, device='cuda:0')\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.3361, device='cuda:0')\n",
      "encoder.block.10.layer.0.layer_norm.weight : tensor(0.2107, device='cuda:0') tensor(0.0923, device='cuda:0')\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0051, device='cuda:0') tensor(0.2959, device='cuda:0')\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0004, device='cuda:0') tensor(0.4312, device='cuda:0')\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.2891, device='cuda:0')\n",
      "encoder.block.10.layer.1.layer_norm.weight : tensor(0.1661, device='cuda:0') tensor(0.0608, device='cuda:0')\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight : tensor(9.8648e-05, device='cuda:0') tensor(0.0355, device='cuda:0')\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight : tensor(-0.0004, device='cuda:0') tensor(0.2932, device='cuda:0')\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight : tensor(0.0002, device='cuda:0') tensor(0.2497, device='cuda:0')\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight : tensor(-7.7923e-05, device='cuda:0') tensor(0.3280, device='cuda:0')\n",
      "encoder.block.11.layer.0.layer_norm.weight : tensor(0.2365, device='cuda:0') tensor(0.1024, device='cuda:0')\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0053, device='cuda:0') tensor(0.2936, device='cuda:0')\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0004, device='cuda:0') tensor(0.4755, device='cuda:0')\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.2932, device='cuda:0')\n",
      "encoder.block.11.layer.1.layer_norm.weight : tensor(0.1669, device='cuda:0') tensor(0.0568, device='cuda:0')\n",
      "encoder.block.12.layer.0.SelfAttention.q.weight : tensor(-4.7712e-05, device='cuda:0') tensor(0.0348, device='cuda:0')\n",
      "encoder.block.12.layer.0.SelfAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.2835, device='cuda:0')\n",
      "encoder.block.12.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.2678, device='cuda:0')\n",
      "encoder.block.12.layer.0.SelfAttention.o.weight : tensor(2.7434e-05, device='cuda:0') tensor(0.3409, device='cuda:0')\n",
      "encoder.block.12.layer.0.layer_norm.weight : tensor(0.2177, device='cuda:0') tensor(0.1082, device='cuda:0')\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0051, device='cuda:0') tensor(0.2858, device='cuda:0')\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.4952, device='cuda:0')\n",
      "encoder.block.12.layer.1.DenseReluDense.wo.weight : tensor(-0.0001, device='cuda:0') tensor(0.3019, device='cuda:0')\n",
      "encoder.block.12.layer.1.layer_norm.weight : tensor(0.1688, device='cuda:0') tensor(0.0578, device='cuda:0')\n",
      "encoder.block.13.layer.0.SelfAttention.q.weight : tensor(4.6887e-05, device='cuda:0') tensor(0.0362, device='cuda:0')\n",
      "encoder.block.13.layer.0.SelfAttention.k.weight : tensor(-0.0006, device='cuda:0') tensor(0.2884, device='cuda:0')\n",
      "encoder.block.13.layer.0.SelfAttention.v.weight : tensor(9.8740e-05, device='cuda:0') tensor(0.2793, device='cuda:0')\n",
      "encoder.block.13.layer.0.SelfAttention.o.weight : tensor(-0.0005, device='cuda:0') tensor(0.3562, device='cuda:0')\n",
      "encoder.block.13.layer.0.layer_norm.weight : tensor(0.2157, device='cuda:0') tensor(0.0993, device='cuda:0')\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0050, device='cuda:0') tensor(0.2821, device='cuda:0')\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0008, device='cuda:0') tensor(0.5181, device='cuda:0')\n",
      "encoder.block.13.layer.1.DenseReluDense.wo.weight : tensor(-0.0001, device='cuda:0') tensor(0.3104, device='cuda:0')\n",
      "encoder.block.13.layer.1.layer_norm.weight : tensor(0.1707, device='cuda:0') tensor(0.0568, device='cuda:0')\n",
      "encoder.block.14.layer.0.SelfAttention.q.weight : tensor(2.4594e-05, device='cuda:0') tensor(0.0336, device='cuda:0')\n",
      "encoder.block.14.layer.0.SelfAttention.k.weight : tensor(-0.0004, device='cuda:0') tensor(0.2734, device='cuda:0')\n",
      "encoder.block.14.layer.0.SelfAttention.v.weight : tensor(-0.0001, device='cuda:0') tensor(0.3343, device='cuda:0')\n",
      "encoder.block.14.layer.0.SelfAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.4000, device='cuda:0')\n",
      "encoder.block.14.layer.0.layer_norm.weight : tensor(0.2227, device='cuda:0') tensor(0.0965, device='cuda:0')\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0043, device='cuda:0') tensor(0.2784, device='cuda:0')\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0002, device='cuda:0') tensor(0.5566, device='cuda:0')\n",
      "encoder.block.14.layer.1.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3205, device='cuda:0')\n",
      "encoder.block.14.layer.1.layer_norm.weight : tensor(0.1610, device='cuda:0') tensor(0.0501, device='cuda:0')\n",
      "encoder.block.15.layer.0.SelfAttention.q.weight : tensor(-3.5173e-05, device='cuda:0') tensor(0.0313, device='cuda:0')\n",
      "encoder.block.15.layer.0.SelfAttention.k.weight : tensor(-8.2549e-05, device='cuda:0') tensor(0.2618, device='cuda:0')\n",
      "encoder.block.15.layer.0.SelfAttention.v.weight : tensor(-0.0003, device='cuda:0') tensor(0.3516, device='cuda:0')\n",
      "encoder.block.15.layer.0.SelfAttention.o.weight : tensor(0.0003, device='cuda:0') tensor(0.4009, device='cuda:0')\n",
      "encoder.block.15.layer.0.layer_norm.weight : tensor(0.2306, device='cuda:0') tensor(0.0944, device='cuda:0')\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0037, device='cuda:0') tensor(0.2717, device='cuda:0')\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0011, device='cuda:0') tensor(0.5933, device='cuda:0')\n",
      "encoder.block.15.layer.1.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3222, device='cuda:0')\n",
      "encoder.block.15.layer.1.layer_norm.weight : tensor(0.1629, device='cuda:0') tensor(0.0481, device='cuda:0')\n",
      "encoder.block.16.layer.0.SelfAttention.q.weight : tensor(-1.1956e-05, device='cuda:0') tensor(0.0309, device='cuda:0')\n",
      "encoder.block.16.layer.0.SelfAttention.k.weight : tensor(6.0728e-05, device='cuda:0') tensor(0.2514, device='cuda:0')\n",
      "encoder.block.16.layer.0.SelfAttention.v.weight : tensor(2.2244e-06, device='cuda:0') tensor(0.3692, device='cuda:0')\n",
      "encoder.block.16.layer.0.SelfAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.4214, device='cuda:0')\n",
      "encoder.block.16.layer.0.layer_norm.weight : tensor(0.2398, device='cuda:0') tensor(0.0954, device='cuda:0')\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0027, device='cuda:0') tensor(0.2726, device='cuda:0')\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0002, device='cuda:0') tensor(0.5790, device='cuda:0')\n",
      "encoder.block.16.layer.1.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.3231, device='cuda:0')\n",
      "encoder.block.16.layer.1.layer_norm.weight : tensor(0.1628, device='cuda:0') tensor(0.0470, device='cuda:0')\n",
      "encoder.block.17.layer.0.SelfAttention.q.weight : tensor(2.5994e-05, device='cuda:0') tensor(0.0268, device='cuda:0')\n",
      "encoder.block.17.layer.0.SelfAttention.k.weight : tensor(5.8277e-05, device='cuda:0') tensor(0.2224, device='cuda:0')\n",
      "encoder.block.17.layer.0.SelfAttention.v.weight : tensor(0.0003, device='cuda:0') tensor(0.4029, device='cuda:0')\n",
      "encoder.block.17.layer.0.SelfAttention.o.weight : tensor(-6.2408e-05, device='cuda:0') tensor(0.4310, device='cuda:0')\n",
      "encoder.block.17.layer.0.layer_norm.weight : tensor(0.2556, device='cuda:0') tensor(0.1098, device='cuda:0')\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0032, device='cuda:0') tensor(0.2695, device='cuda:0')\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0011, device='cuda:0') tensor(0.6116, device='cuda:0')\n",
      "encoder.block.17.layer.1.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.3257, device='cuda:0')\n",
      "encoder.block.17.layer.1.layer_norm.weight : tensor(0.1659, device='cuda:0') tensor(0.0451, device='cuda:0')\n",
      "encoder.block.18.layer.0.SelfAttention.q.weight : tensor(-2.3633e-05, device='cuda:0') tensor(0.0272, device='cuda:0')\n",
      "encoder.block.18.layer.0.SelfAttention.k.weight : tensor(-9.4914e-05, device='cuda:0') tensor(0.2159, device='cuda:0')\n",
      "encoder.block.18.layer.0.SelfAttention.v.weight : tensor(0.0001, device='cuda:0') tensor(0.4569, device='cuda:0')\n",
      "encoder.block.18.layer.0.SelfAttention.o.weight : tensor(0.0004, device='cuda:0') tensor(0.4802, device='cuda:0')\n",
      "encoder.block.18.layer.0.layer_norm.weight : tensor(0.2592, device='cuda:0') tensor(0.0908, device='cuda:0')\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0026, device='cuda:0') tensor(0.2697, device='cuda:0')\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_1.weight : tensor(0.0003, device='cuda:0') tensor(0.5960, device='cuda:0')\n",
      "encoder.block.18.layer.1.DenseReluDense.wo.weight : tensor(3.4971e-06, device='cuda:0') tensor(0.3322, device='cuda:0')\n",
      "encoder.block.18.layer.1.layer_norm.weight : tensor(0.1665, device='cuda:0') tensor(0.0384, device='cuda:0')\n",
      "encoder.block.19.layer.0.SelfAttention.q.weight : tensor(-3.3360e-05, device='cuda:0') tensor(0.0275, device='cuda:0')\n",
      "encoder.block.19.layer.0.SelfAttention.k.weight : tensor(1.2220e-05, device='cuda:0') tensor(0.2208, device='cuda:0')\n",
      "encoder.block.19.layer.0.SelfAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.4716, device='cuda:0')\n",
      "encoder.block.19.layer.0.SelfAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.4967, device='cuda:0')\n",
      "encoder.block.19.layer.0.layer_norm.weight : tensor(0.2483, device='cuda:0') tensor(0.0747, device='cuda:0')\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0018, device='cuda:0') tensor(0.2613, device='cuda:0')\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0008, device='cuda:0') tensor(0.6241, device='cuda:0')\n",
      "encoder.block.19.layer.1.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3552, device='cuda:0')\n",
      "encoder.block.19.layer.1.layer_norm.weight : tensor(0.1690, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "encoder.block.20.layer.0.SelfAttention.q.weight : tensor(4.4681e-05, device='cuda:0') tensor(0.0262, device='cuda:0')\n",
      "encoder.block.20.layer.0.SelfAttention.k.weight : tensor(0.0003, device='cuda:0') tensor(0.2073, device='cuda:0')\n",
      "encoder.block.20.layer.0.SelfAttention.v.weight : tensor(0.0007, device='cuda:0') tensor(0.5366, device='cuda:0')\n",
      "encoder.block.20.layer.0.SelfAttention.o.weight : tensor(0.0005, device='cuda:0') tensor(0.5215, device='cuda:0')\n",
      "encoder.block.20.layer.0.layer_norm.weight : tensor(0.2487, device='cuda:0') tensor(0.0730, device='cuda:0')\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0021, device='cuda:0') tensor(0.2671, device='cuda:0')\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.6544, device='cuda:0')\n",
      "encoder.block.20.layer.1.DenseReluDense.wo.weight : tensor(-0.0001, device='cuda:0') tensor(0.3556, device='cuda:0')\n",
      "encoder.block.20.layer.1.layer_norm.weight : tensor(0.1732, device='cuda:0') tensor(0.0333, device='cuda:0')\n",
      "encoder.block.21.layer.0.SelfAttention.q.weight : tensor(7.4901e-06, device='cuda:0') tensor(0.0250, device='cuda:0')\n",
      "encoder.block.21.layer.0.SelfAttention.k.weight : tensor(6.5801e-05, device='cuda:0') tensor(0.1982, device='cuda:0')\n",
      "encoder.block.21.layer.0.SelfAttention.v.weight : tensor(-0.0006, device='cuda:0') tensor(0.5456, device='cuda:0')\n",
      "encoder.block.21.layer.0.SelfAttention.o.weight : tensor(-0.0011, device='cuda:0') tensor(0.5427, device='cuda:0')\n",
      "encoder.block.21.layer.0.layer_norm.weight : tensor(0.2556, device='cuda:0') tensor(0.0742, device='cuda:0')\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0024, device='cuda:0') tensor(0.2682, device='cuda:0')\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_1.weight : tensor(2.7313e-05, device='cuda:0') tensor(0.6728, device='cuda:0')\n",
      "encoder.block.21.layer.1.DenseReluDense.wo.weight : tensor(-5.9869e-05, device='cuda:0') tensor(0.3580, device='cuda:0')\n",
      "encoder.block.21.layer.1.layer_norm.weight : tensor(0.1723, device='cuda:0') tensor(0.0287, device='cuda:0')\n",
      "encoder.block.22.layer.0.SelfAttention.q.weight : tensor(-4.2840e-05, device='cuda:0') tensor(0.0231, device='cuda:0')\n",
      "encoder.block.22.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.1824, device='cuda:0')\n",
      "encoder.block.22.layer.0.SelfAttention.v.weight : tensor(-0.0007, device='cuda:0') tensor(0.6530, device='cuda:0')\n",
      "encoder.block.22.layer.0.SelfAttention.o.weight : tensor(0.0003, device='cuda:0') tensor(0.6115, device='cuda:0')\n",
      "encoder.block.22.layer.0.layer_norm.weight : tensor(0.2471, device='cuda:0') tensor(0.0680, device='cuda:0')\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0016, device='cuda:0') tensor(0.2651, device='cuda:0')\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0003, device='cuda:0') tensor(0.6861, device='cuda:0')\n",
      "encoder.block.22.layer.1.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.3641, device='cuda:0')\n",
      "encoder.block.22.layer.1.layer_norm.weight : tensor(0.1695, device='cuda:0') tensor(0.0357, device='cuda:0')\n",
      "encoder.block.23.layer.0.SelfAttention.q.weight : tensor(-1.1794e-06, device='cuda:0') tensor(0.0218, device='cuda:0')\n",
      "encoder.block.23.layer.0.SelfAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.1688, device='cuda:0')\n",
      "encoder.block.23.layer.0.SelfAttention.v.weight : tensor(0.0003, device='cuda:0') tensor(0.6225, device='cuda:0')\n",
      "encoder.block.23.layer.0.SelfAttention.o.weight : tensor(-0.0006, device='cuda:0') tensor(0.5932, device='cuda:0')\n",
      "encoder.block.23.layer.0.layer_norm.weight : tensor(0.2335, device='cuda:0') tensor(0.0665, device='cuda:0')\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_0.weight : tensor(-0.0008, device='cuda:0') tensor(0.2898, device='cuda:0')\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_1.weight : tensor(-0.0009, device='cuda:0') tensor(0.7307, device='cuda:0')\n",
      "encoder.block.23.layer.1.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.3808, device='cuda:0')\n",
      "encoder.block.23.layer.1.layer_norm.weight : tensor(0.1394, device='cuda:0') tensor(0.0340, device='cuda:0')\n",
      "encoder.final_layer_norm.weight : tensor(0.1188, device='cuda:0') tensor(0.0278, device='cuda:0')\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight : tensor(2.5208e-05, device='cuda:0') tensor(0.0149, device='cuda:0')\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.1323, device='cuda:0')\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight : tensor(3.9140e-05, device='cuda:0') tensor(0.0788, device='cuda:0')\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight : tensor(0.0001, device='cuda:0') tensor(0.1123, device='cuda:0')\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight : tensor(-0.3844, device='cuda:0') tensor(2.9142, device='cuda:0')\n",
      "decoder.block.0.layer.0.layer_norm.weight : tensor(0.2320, device='cuda:0') tensor(0.0829, device='cuda:0')\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight : tensor(-5.8491e-05, device='cuda:0') tensor(0.0331, device='cuda:0')\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.2698, device='cuda:0')\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight : tensor(9.1037e-05, device='cuda:0') tensor(0.2094, device='cuda:0')\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight : tensor(0.0001, device='cuda:0') tensor(0.2019, device='cuda:0')\n",
      "decoder.block.0.layer.1.layer_norm.weight : tensor(0.2254, device='cuda:0') tensor(0.0573, device='cuda:0')\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0101, device='cuda:0') tensor(0.2438, device='cuda:0')\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.2038, device='cuda:0')\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.1522, device='cuda:0')\n",
      "decoder.block.0.layer.2.layer_norm.weight : tensor(0.0933, device='cuda:0') tensor(0.0180, device='cuda:0')\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight : tensor(2.1172e-06, device='cuda:0') tensor(0.0096, device='cuda:0')\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.0761, device='cuda:0')\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight : tensor(-2.1211e-05, device='cuda:0') tensor(0.0543, device='cuda:0')\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight : tensor(-3.4306e-06, device='cuda:0') tensor(0.0726, device='cuda:0')\n",
      "decoder.block.1.layer.0.layer_norm.weight : tensor(0.2852, device='cuda:0') tensor(0.1120, device='cuda:0')\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight : tensor(-2.6056e-05, device='cuda:0') tensor(0.0194, device='cuda:0')\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight : tensor(-6.6035e-05, device='cuda:0') tensor(0.1792, device='cuda:0')\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.2226, device='cuda:0')\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.1563, device='cuda:0')\n",
      "decoder.block.1.layer.1.layer_norm.weight : tensor(0.5642, device='cuda:0') tensor(0.3796, device='cuda:0')\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0014, device='cuda:0') tensor(0.1536, device='cuda:0')\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0004, device='cuda:0') tensor(0.1581, device='cuda:0')\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.1310, device='cuda:0')\n",
      "decoder.block.1.layer.2.layer_norm.weight : tensor(0.2390, device='cuda:0') tensor(0.0655, device='cuda:0')\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight : tensor(5.8541e-07, device='cuda:0') tensor(0.0083, device='cuda:0')\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.0737, device='cuda:0')\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight : tensor(-2.7189e-05, device='cuda:0') tensor(0.0479, device='cuda:0')\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight : tensor(-2.6848e-05, device='cuda:0') tensor(0.0674, device='cuda:0')\n",
      "decoder.block.2.layer.0.layer_norm.weight : tensor(0.5752, device='cuda:0') tensor(0.1943, device='cuda:0')\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight : tensor(3.9646e-05, device='cuda:0') tensor(0.0259, device='cuda:0')\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight : tensor(0.0004, device='cuda:0') tensor(0.1897, device='cuda:0')\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight : tensor(2.8222e-05, device='cuda:0') tensor(0.2006, device='cuda:0')\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.1715, device='cuda:0')\n",
      "decoder.block.2.layer.1.layer_norm.weight : tensor(0.7081, device='cuda:0') tensor(0.3500, device='cuda:0')\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0006, device='cuda:0') tensor(0.1818, device='cuda:0')\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.1866, device='cuda:0')\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.1521, device='cuda:0')\n",
      "decoder.block.2.layer.2.layer_norm.weight : tensor(0.2537, device='cuda:0') tensor(0.0741, device='cuda:0')\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight : tensor(-1.4745e-05, device='cuda:0') tensor(0.0123, device='cuda:0')\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight : tensor(-9.3155e-05, device='cuda:0') tensor(0.1033, device='cuda:0')\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight : tensor(6.1708e-05, device='cuda:0') tensor(0.0579, device='cuda:0')\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight : tensor(0.0001, device='cuda:0') tensor(0.0770, device='cuda:0')\n",
      "decoder.block.3.layer.0.layer_norm.weight : tensor(0.4394, device='cuda:0') tensor(0.2220, device='cuda:0')\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight : tensor(1.6472e-06, device='cuda:0') tensor(0.0362, device='cuda:0')\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.2456, device='cuda:0')\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight : tensor(-0.0003, device='cuda:0') tensor(0.2484, device='cuda:0')\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight : tensor(0.0003, device='cuda:0') tensor(0.1357, device='cuda:0')\n",
      "decoder.block.3.layer.1.layer_norm.weight : tensor(0.3253, device='cuda:0') tensor(0.1813, device='cuda:0')\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0018, device='cuda:0') tensor(0.2031, device='cuda:0')\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0008, device='cuda:0') tensor(0.2165, device='cuda:0')\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight : tensor(-0.0004, device='cuda:0') tensor(0.1876, device='cuda:0')\n",
      "decoder.block.3.layer.2.layer_norm.weight : tensor(0.2529, device='cuda:0') tensor(0.0781, device='cuda:0')\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight : tensor(2.9639e-05, device='cuda:0') tensor(0.0182, device='cuda:0')\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.1676, device='cuda:0')\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight : tensor(4.1599e-06, device='cuda:0') tensor(0.0805, device='cuda:0')\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight : tensor(-8.5618e-05, device='cuda:0') tensor(0.1534, device='cuda:0')\n",
      "decoder.block.4.layer.0.layer_norm.weight : tensor(0.4652, device='cuda:0') tensor(0.1802, device='cuda:0')\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight : tensor(-1.7620e-05, device='cuda:0') tensor(0.0237, device='cuda:0')\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight : tensor(-6.9806e-07, device='cuda:0') tensor(0.1969, device='cuda:0')\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.2144, device='cuda:0')\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight : tensor(4.6321e-05, device='cuda:0') tensor(0.2375, device='cuda:0')\n",
      "decoder.block.4.layer.1.layer_norm.weight : tensor(1.0439, device='cuda:0') tensor(0.4979, device='cuda:0')\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0019, device='cuda:0') tensor(0.1960, device='cuda:0')\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0010, device='cuda:0') tensor(0.2120, device='cuda:0')\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.2451, device='cuda:0')\n",
      "decoder.block.4.layer.2.layer_norm.weight : tensor(0.3884, device='cuda:0') tensor(0.1082, device='cuda:0')\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight : tensor(-7.4051e-06, device='cuda:0') tensor(0.0176, device='cuda:0')\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.1302, device='cuda:0')\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.0796, device='cuda:0')\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight : tensor(0.0002, device='cuda:0') tensor(0.1981, device='cuda:0')\n",
      "decoder.block.5.layer.0.layer_norm.weight : tensor(0.9442, device='cuda:0') tensor(0.2659, device='cuda:0')\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight : tensor(-1.8767e-05, device='cuda:0') tensor(0.0263, device='cuda:0')\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.1979, device='cuda:0')\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.1990, device='cuda:0')\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight : tensor(0.0004, device='cuda:0') tensor(0.2607, device='cuda:0')\n",
      "decoder.block.5.layer.1.layer_norm.weight : tensor(1.6169, device='cuda:0') tensor(0.7564, device='cuda:0')\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0036, device='cuda:0') tensor(0.2169, device='cuda:0')\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.2415, device='cuda:0')\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight : tensor(-0.0009, device='cuda:0') tensor(0.3157, device='cuda:0')\n",
      "decoder.block.5.layer.2.layer_norm.weight : tensor(0.4884, device='cuda:0') tensor(0.1298, device='cuda:0')\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight : tensor(3.7463e-05, device='cuda:0') tensor(0.0299, device='cuda:0')\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.2745, device='cuda:0')\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.1202, device='cuda:0')\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight : tensor(-0.0001, device='cuda:0') tensor(0.3271, device='cuda:0')\n",
      "decoder.block.6.layer.0.layer_norm.weight : tensor(0.6888, device='cuda:0') tensor(0.2202, device='cuda:0')\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight : tensor(1.3492e-05, device='cuda:0') tensor(0.0183, device='cuda:0')\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight : tensor(-8.8098e-05, device='cuda:0') tensor(0.1253, device='cuda:0')\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight : tensor(0.0002, device='cuda:0') tensor(0.1315, device='cuda:0')\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight : tensor(0.0002, device='cuda:0') tensor(0.3248, device='cuda:0')\n",
      "decoder.block.6.layer.1.layer_norm.weight : tensor(5.8830, device='cuda:0') tensor(2.7461, device='cuda:0')\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0068, device='cuda:0') tensor(0.3119, device='cuda:0')\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0003, device='cuda:0') tensor(0.3238, device='cuda:0')\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.7608, device='cuda:0')\n",
      "decoder.block.6.layer.2.layer_norm.weight : tensor(0.4435, device='cuda:0') tensor(0.1167, device='cuda:0')\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight : tensor(6.0921e-05, device='cuda:0') tensor(0.0408, device='cuda:0')\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight : tensor(-0.0003, device='cuda:0') tensor(0.3818, device='cuda:0')\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight : tensor(3.5343e-05, device='cuda:0') tensor(0.2092, device='cuda:0')\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight : tensor(0.0003, device='cuda:0') tensor(0.3585, device='cuda:0')\n",
      "decoder.block.7.layer.0.layer_norm.weight : tensor(0.8667, device='cuda:0') tensor(0.2816, device='cuda:0')\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight : tensor(-3.1212e-05, device='cuda:0') tensor(0.0277, device='cuda:0')\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight : tensor(-1.6119e-05, device='cuda:0') tensor(0.2290, device='cuda:0')\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight : tensor(-3.0032e-05, device='cuda:0') tensor(0.2064, device='cuda:0')\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight : tensor(0.0003, device='cuda:0') tensor(0.3008, device='cuda:0')\n",
      "decoder.block.7.layer.1.layer_norm.weight : tensor(2.8372, device='cuda:0') tensor(1.3625, device='cuda:0')\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0131, device='cuda:0') tensor(0.3544, device='cuda:0')\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0008, device='cuda:0') tensor(0.3834, device='cuda:0')\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.4093, device='cuda:0')\n",
      "decoder.block.7.layer.2.layer_norm.weight : tensor(0.6169, device='cuda:0') tensor(0.1651, device='cuda:0')\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight : tensor(-4.9799e-06, device='cuda:0') tensor(0.0548, device='cuda:0')\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight : tensor(-0.0004, device='cuda:0') tensor(0.4500, device='cuda:0')\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight : tensor(0.0003, device='cuda:0') tensor(0.2649, device='cuda:0')\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.4411, device='cuda:0')\n",
      "decoder.block.8.layer.0.layer_norm.weight : tensor(0.7531, device='cuda:0') tensor(0.2438, device='cuda:0')\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight : tensor(-2.2590e-05, device='cuda:0') tensor(0.0412, device='cuda:0')\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight : tensor(-6.9685e-05, device='cuda:0') tensor(0.3628, device='cuda:0')\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight : tensor(-9.5583e-05, device='cuda:0') tensor(0.2432, device='cuda:0')\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight : tensor(-0.0004, device='cuda:0') tensor(0.3590, device='cuda:0')\n",
      "decoder.block.8.layer.1.layer_norm.weight : tensor(1.1246, device='cuda:0') tensor(0.6766, device='cuda:0')\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0122, device='cuda:0') tensor(0.3518, device='cuda:0')\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.4362, device='cuda:0')\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.4058, device='cuda:0')\n",
      "decoder.block.8.layer.2.layer_norm.weight : tensor(0.6219, device='cuda:0') tensor(0.1533, device='cuda:0')\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight : tensor(-9.9639e-05, device='cuda:0') tensor(0.0499, device='cuda:0')\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight : tensor(0.0007, device='cuda:0') tensor(0.4079, device='cuda:0')\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.2942, device='cuda:0')\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight : tensor(0.0008, device='cuda:0') tensor(0.4342, device='cuda:0')\n",
      "decoder.block.9.layer.0.layer_norm.weight : tensor(0.7864, device='cuda:0') tensor(0.2367, device='cuda:0')\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight : tensor(2.3766e-05, device='cuda:0') tensor(0.0413, device='cuda:0')\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight : tensor(0.0003, device='cuda:0') tensor(0.3818, device='cuda:0')\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight : tensor(0.0001, device='cuda:0') tensor(0.2624, device='cuda:0')\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight : tensor(0.0005, device='cuda:0') tensor(0.3382, device='cuda:0')\n",
      "decoder.block.9.layer.1.layer_norm.weight : tensor(1.0383, device='cuda:0') tensor(0.6126, device='cuda:0')\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0117, device='cuda:0') tensor(0.3570, device='cuda:0')\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0008, device='cuda:0') tensor(0.4788, device='cuda:0')\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight : tensor(-0.0005, device='cuda:0') tensor(0.3831, device='cuda:0')\n",
      "decoder.block.9.layer.2.layer_norm.weight : tensor(0.5894, device='cuda:0') tensor(0.1329, device='cuda:0')\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight : tensor(-7.3992e-05, device='cuda:0') tensor(0.0521, device='cuda:0')\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.4017, device='cuda:0')\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight : tensor(-0.0004, device='cuda:0') tensor(0.3427, device='cuda:0')\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight : tensor(-0.0005, device='cuda:0') tensor(0.4875, device='cuda:0')\n",
      "decoder.block.10.layer.0.layer_norm.weight : tensor(0.7266, device='cuda:0') tensor(0.2308, device='cuda:0')\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight : tensor(-2.8619e-05, device='cuda:0') tensor(0.0401, device='cuda:0')\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight : tensor(-4.0321e-05, device='cuda:0') tensor(0.3820, device='cuda:0')\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight : tensor(-5.1769e-05, device='cuda:0') tensor(0.2787, device='cuda:0')\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.4100, device='cuda:0')\n",
      "decoder.block.10.layer.1.layer_norm.weight : tensor(1.0203, device='cuda:0') tensor(0.5946, device='cuda:0')\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0093, device='cuda:0') tensor(0.3378, device='cuda:0')\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0010, device='cuda:0') tensor(0.5060, device='cuda:0')\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.3840, device='cuda:0')\n",
      "decoder.block.10.layer.2.layer_norm.weight : tensor(0.5720, device='cuda:0') tensor(0.1238, device='cuda:0')\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight : tensor(-3.8550e-05, device='cuda:0') tensor(0.0540, device='cuda:0')\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.4307, device='cuda:0')\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.3868, device='cuda:0')\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight : tensor(-0.0004, device='cuda:0') tensor(0.4725, device='cuda:0')\n",
      "decoder.block.11.layer.0.layer_norm.weight : tensor(0.6690, device='cuda:0') tensor(0.2133, device='cuda:0')\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight : tensor(4.5369e-05, device='cuda:0') tensor(0.0446, device='cuda:0')\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.3918, device='cuda:0')\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight : tensor(4.9623e-05, device='cuda:0') tensor(0.3152, device='cuda:0')\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight : tensor(-0.0007, device='cuda:0') tensor(0.4107, device='cuda:0')\n",
      "decoder.block.11.layer.1.layer_norm.weight : tensor(0.8461, device='cuda:0') tensor(0.5355, device='cuda:0')\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0082, device='cuda:0') tensor(0.3237, device='cuda:0')\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0002, device='cuda:0') tensor(0.5346, device='cuda:0')\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight : tensor(-0.0005, device='cuda:0') tensor(0.3943, device='cuda:0')\n",
      "decoder.block.11.layer.2.layer_norm.weight : tensor(0.5907, device='cuda:0') tensor(0.1123, device='cuda:0')\n",
      "decoder.block.12.layer.0.SelfAttention.q.weight : tensor(-4.0085e-05, device='cuda:0') tensor(0.0496, device='cuda:0')\n",
      "decoder.block.12.layer.0.SelfAttention.k.weight : tensor(-0.0004, device='cuda:0') tensor(0.3933, device='cuda:0')\n",
      "decoder.block.12.layer.0.SelfAttention.v.weight : tensor(-0.0006, device='cuda:0') tensor(0.4114, device='cuda:0')\n",
      "decoder.block.12.layer.0.SelfAttention.o.weight : tensor(0.0002, device='cuda:0') tensor(0.4916, device='cuda:0')\n",
      "decoder.block.12.layer.0.layer_norm.weight : tensor(0.7034, device='cuda:0') tensor(0.2226, device='cuda:0')\n",
      "decoder.block.12.layer.1.EncDecAttention.q.weight : tensor(7.4689e-06, device='cuda:0') tensor(0.0419, device='cuda:0')\n",
      "decoder.block.12.layer.1.EncDecAttention.k.weight : tensor(8.0237e-05, device='cuda:0') tensor(0.3836, device='cuda:0')\n",
      "decoder.block.12.layer.1.EncDecAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.3679, device='cuda:0')\n",
      "decoder.block.12.layer.1.EncDecAttention.o.weight : tensor(7.7673e-05, device='cuda:0') tensor(0.4160, device='cuda:0')\n",
      "decoder.block.12.layer.1.layer_norm.weight : tensor(0.8335, device='cuda:0') tensor(0.4341, device='cuda:0')\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0079, device='cuda:0') tensor(0.3141, device='cuda:0')\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.5580, device='cuda:0')\n",
      "decoder.block.12.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3892, device='cuda:0')\n",
      "decoder.block.12.layer.2.layer_norm.weight : tensor(0.5837, device='cuda:0') tensor(0.1000, device='cuda:0')\n",
      "decoder.block.13.layer.0.SelfAttention.q.weight : tensor(0.0001, device='cuda:0') tensor(0.0495, device='cuda:0')\n",
      "decoder.block.13.layer.0.SelfAttention.k.weight : tensor(0.0005, device='cuda:0') tensor(0.3929, device='cuda:0')\n",
      "decoder.block.13.layer.0.SelfAttention.v.weight : tensor(-0.0003, device='cuda:0') tensor(0.4055, device='cuda:0')\n",
      "decoder.block.13.layer.0.SelfAttention.o.weight : tensor(0.0008, device='cuda:0') tensor(0.5565, device='cuda:0')\n",
      "decoder.block.13.layer.0.layer_norm.weight : tensor(0.6858, device='cuda:0') tensor(0.2281, device='cuda:0')\n",
      "decoder.block.13.layer.1.EncDecAttention.q.weight : tensor(0.0001, device='cuda:0') tensor(0.0436, device='cuda:0')\n",
      "decoder.block.13.layer.1.EncDecAttention.k.weight : tensor(-0.0003, device='cuda:0') tensor(0.4033, device='cuda:0')\n",
      "decoder.block.13.layer.1.EncDecAttention.v.weight : tensor(0.0002, device='cuda:0') tensor(0.3930, device='cuda:0')\n",
      "decoder.block.13.layer.1.EncDecAttention.o.weight : tensor(0.0008, device='cuda:0') tensor(0.4141, device='cuda:0')\n",
      "decoder.block.13.layer.1.layer_norm.weight : tensor(0.7695, device='cuda:0') tensor(0.3995, device='cuda:0')\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0069, device='cuda:0') tensor(0.3039, device='cuda:0')\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.5889, device='cuda:0')\n",
      "decoder.block.13.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3991, device='cuda:0')\n",
      "decoder.block.13.layer.2.layer_norm.weight : tensor(0.6044, device='cuda:0') tensor(0.0979, device='cuda:0')\n",
      "decoder.block.14.layer.0.SelfAttention.q.weight : tensor(2.4869e-05, device='cuda:0') tensor(0.0468, device='cuda:0')\n",
      "decoder.block.14.layer.0.SelfAttention.k.weight : tensor(-0.0009, device='cuda:0') tensor(0.3679, device='cuda:0')\n",
      "decoder.block.14.layer.0.SelfAttention.v.weight : tensor(0.0001, device='cuda:0') tensor(0.4259, device='cuda:0')\n",
      "decoder.block.14.layer.0.SelfAttention.o.weight : tensor(0.0002, device='cuda:0') tensor(0.5291, device='cuda:0')\n",
      "decoder.block.14.layer.0.layer_norm.weight : tensor(0.7112, device='cuda:0') tensor(0.1916, device='cuda:0')\n",
      "decoder.block.14.layer.1.EncDecAttention.q.weight : tensor(-1.6641e-05, device='cuda:0') tensor(0.0434, device='cuda:0')\n",
      "decoder.block.14.layer.1.EncDecAttention.k.weight : tensor(-0.0001, device='cuda:0') tensor(0.3859, device='cuda:0')\n",
      "decoder.block.14.layer.1.EncDecAttention.v.weight : tensor(-3.0098e-05, device='cuda:0') tensor(0.4208, device='cuda:0')\n",
      "decoder.block.14.layer.1.EncDecAttention.o.weight : tensor(-0.0005, device='cuda:0') tensor(0.4973, device='cuda:0')\n",
      "decoder.block.14.layer.1.layer_norm.weight : tensor(0.6831, device='cuda:0') tensor(0.3861, device='cuda:0')\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0070, device='cuda:0') tensor(0.3015, device='cuda:0')\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.6242, device='cuda:0')\n",
      "decoder.block.14.layer.2.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.3880, device='cuda:0')\n",
      "decoder.block.14.layer.2.layer_norm.weight : tensor(0.6017, device='cuda:0') tensor(0.0883, device='cuda:0')\n",
      "decoder.block.15.layer.0.SelfAttention.q.weight : tensor(7.9275e-05, device='cuda:0') tensor(0.0479, device='cuda:0')\n",
      "decoder.block.15.layer.0.SelfAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.3810, device='cuda:0')\n",
      "decoder.block.15.layer.0.SelfAttention.v.weight : tensor(0.0008, device='cuda:0') tensor(0.4924, device='cuda:0')\n",
      "decoder.block.15.layer.0.SelfAttention.o.weight : tensor(-0.0012, device='cuda:0') tensor(0.5276, device='cuda:0')\n",
      "decoder.block.15.layer.0.layer_norm.weight : tensor(0.6669, device='cuda:0') tensor(0.2131, device='cuda:0')\n",
      "decoder.block.15.layer.1.EncDecAttention.q.weight : tensor(7.9568e-06, device='cuda:0') tensor(0.0420, device='cuda:0')\n",
      "decoder.block.15.layer.1.EncDecAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.3737, device='cuda:0')\n",
      "decoder.block.15.layer.1.EncDecAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.4637, device='cuda:0')\n",
      "decoder.block.15.layer.1.EncDecAttention.o.weight : tensor(-0.0005, device='cuda:0') tensor(0.4823, device='cuda:0')\n",
      "decoder.block.15.layer.1.layer_norm.weight : tensor(0.7281, device='cuda:0') tensor(0.4835, device='cuda:0')\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0061, device='cuda:0') tensor(0.2893, device='cuda:0')\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0004, device='cuda:0') tensor(0.6330, device='cuda:0')\n",
      "decoder.block.15.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3866, device='cuda:0')\n",
      "decoder.block.15.layer.2.layer_norm.weight : tensor(0.6326, device='cuda:0') tensor(0.0868, device='cuda:0')\n",
      "decoder.block.16.layer.0.SelfAttention.q.weight : tensor(-7.2826e-05, device='cuda:0') tensor(0.0398, device='cuda:0')\n",
      "decoder.block.16.layer.0.SelfAttention.k.weight : tensor(-0.0003, device='cuda:0') tensor(0.3093, device='cuda:0')\n",
      "decoder.block.16.layer.0.SelfAttention.v.weight : tensor(-0.0003, device='cuda:0') tensor(0.4715, device='cuda:0')\n",
      "decoder.block.16.layer.0.SelfAttention.o.weight : tensor(0.0005, device='cuda:0') tensor(0.6971, device='cuda:0')\n",
      "decoder.block.16.layer.0.layer_norm.weight : tensor(0.7627, device='cuda:0') tensor(0.2527, device='cuda:0')\n",
      "decoder.block.16.layer.1.EncDecAttention.q.weight : tensor(6.1227e-05, device='cuda:0') tensor(0.0452, device='cuda:0')\n",
      "decoder.block.16.layer.1.EncDecAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.4082, device='cuda:0')\n",
      "decoder.block.16.layer.1.EncDecAttention.v.weight : tensor(-0.0008, device='cuda:0') tensor(0.5138, device='cuda:0')\n",
      "decoder.block.16.layer.1.EncDecAttention.o.weight : tensor(0.0007, device='cuda:0') tensor(0.5617, device='cuda:0')\n",
      "decoder.block.16.layer.1.layer_norm.weight : tensor(0.5554, device='cuda:0') tensor(0.3493, device='cuda:0')\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0048, device='cuda:0') tensor(0.2896, device='cuda:0')\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_1.weight : tensor(-8.3886e-05, device='cuda:0') tensor(0.6692, device='cuda:0')\n",
      "decoder.block.16.layer.2.DenseReluDense.wo.weight : tensor(-0.0005, device='cuda:0') tensor(0.4010, device='cuda:0')\n",
      "decoder.block.16.layer.2.layer_norm.weight : tensor(0.6166, device='cuda:0') tensor(0.0883, device='cuda:0')\n",
      "decoder.block.17.layer.0.SelfAttention.q.weight : tensor(3.6537e-05, device='cuda:0') tensor(0.0434, device='cuda:0')\n",
      "decoder.block.17.layer.0.SelfAttention.k.weight : tensor(-0.0006, device='cuda:0') tensor(0.3342, device='cuda:0')\n",
      "decoder.block.17.layer.0.SelfAttention.v.weight : tensor(0.0002, device='cuda:0') tensor(0.5457, device='cuda:0')\n",
      "decoder.block.17.layer.0.SelfAttention.o.weight : tensor(-0.0012, device='cuda:0') tensor(0.5088, device='cuda:0')\n",
      "decoder.block.17.layer.0.layer_norm.weight : tensor(0.6669, device='cuda:0') tensor(0.2379, device='cuda:0')\n",
      "decoder.block.17.layer.1.EncDecAttention.q.weight : tensor(4.6734e-05, device='cuda:0') tensor(0.0434, device='cuda:0')\n",
      "decoder.block.17.layer.1.EncDecAttention.k.weight : tensor(0.0008, device='cuda:0') tensor(0.3854, device='cuda:0')\n",
      "decoder.block.17.layer.1.EncDecAttention.v.weight : tensor(-0.0006, device='cuda:0') tensor(0.5295, device='cuda:0')\n",
      "decoder.block.17.layer.1.EncDecAttention.o.weight : tensor(-0.0009, device='cuda:0') tensor(0.5552, device='cuda:0')\n",
      "decoder.block.17.layer.1.layer_norm.weight : tensor(0.6782, device='cuda:0') tensor(0.3829, device='cuda:0')\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0039, device='cuda:0') tensor(0.2807, device='cuda:0')\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0007, device='cuda:0') tensor(0.6972, device='cuda:0')\n",
      "decoder.block.17.layer.2.DenseReluDense.wo.weight : tensor(-0.0006, device='cuda:0') tensor(0.3950, device='cuda:0')\n",
      "decoder.block.17.layer.2.layer_norm.weight : tensor(0.6580, device='cuda:0') tensor(0.0950, device='cuda:0')\n",
      "decoder.block.18.layer.0.SelfAttention.q.weight : tensor(2.4495e-05, device='cuda:0') tensor(0.0418, device='cuda:0')\n",
      "decoder.block.18.layer.0.SelfAttention.k.weight : tensor(0.0007, device='cuda:0') tensor(0.3323, device='cuda:0')\n",
      "decoder.block.18.layer.0.SelfAttention.v.weight : tensor(1.6092e-05, device='cuda:0') tensor(0.5228, device='cuda:0')\n",
      "decoder.block.18.layer.0.SelfAttention.o.weight : tensor(-3.5294e-05, device='cuda:0') tensor(0.5886, device='cuda:0')\n",
      "decoder.block.18.layer.0.layer_norm.weight : tensor(0.6965, device='cuda:0') tensor(0.2227, device='cuda:0')\n",
      "decoder.block.18.layer.1.EncDecAttention.q.weight : tensor(-2.0075e-05, device='cuda:0') tensor(0.0437, device='cuda:0')\n",
      "decoder.block.18.layer.1.EncDecAttention.k.weight : tensor(-4.1281e-05, device='cuda:0') tensor(0.3742, device='cuda:0')\n",
      "decoder.block.18.layer.1.EncDecAttention.v.weight : tensor(8.0402e-05, device='cuda:0') tensor(0.6309, device='cuda:0')\n",
      "decoder.block.18.layer.1.EncDecAttention.o.weight : tensor(0.0004, device='cuda:0') tensor(0.6793, device='cuda:0')\n",
      "decoder.block.18.layer.1.layer_norm.weight : tensor(0.6036, device='cuda:0') tensor(0.4100, device='cuda:0')\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0031, device='cuda:0') tensor(0.2687, device='cuda:0')\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0011, device='cuda:0') tensor(0.7143, device='cuda:0')\n",
      "decoder.block.18.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.3996, device='cuda:0')\n",
      "decoder.block.18.layer.2.layer_norm.weight : tensor(0.6700, device='cuda:0') tensor(0.0965, device='cuda:0')\n",
      "decoder.block.19.layer.0.SelfAttention.q.weight : tensor(-2.1069e-05, device='cuda:0') tensor(0.0400, device='cuda:0')\n",
      "decoder.block.19.layer.0.SelfAttention.k.weight : tensor(-7.8851e-05, device='cuda:0') tensor(0.3205, device='cuda:0')\n",
      "decoder.block.19.layer.0.SelfAttention.v.weight : tensor(-0.0007, device='cuda:0') tensor(0.5929, device='cuda:0')\n",
      "decoder.block.19.layer.0.SelfAttention.o.weight : tensor(-0.0005, device='cuda:0') tensor(0.7288, device='cuda:0')\n",
      "decoder.block.19.layer.0.layer_norm.weight : tensor(0.7072, device='cuda:0') tensor(0.2051, device='cuda:0')\n",
      "decoder.block.19.layer.1.EncDecAttention.q.weight : tensor(2.2553e-06, device='cuda:0') tensor(0.0427, device='cuda:0')\n",
      "decoder.block.19.layer.1.EncDecAttention.k.weight : tensor(-0.0002, device='cuda:0') tensor(0.3662, device='cuda:0')\n",
      "decoder.block.19.layer.1.EncDecAttention.v.weight : tensor(-4.3786e-05, device='cuda:0') tensor(0.6886, device='cuda:0')\n",
      "decoder.block.19.layer.1.EncDecAttention.o.weight : tensor(0.0009, device='cuda:0') tensor(0.7539, device='cuda:0')\n",
      "decoder.block.19.layer.1.layer_norm.weight : tensor(0.5649, device='cuda:0') tensor(0.3582, device='cuda:0')\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0019, device='cuda:0') tensor(0.2646, device='cuda:0')\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0003, device='cuda:0') tensor(0.7432, device='cuda:0')\n",
      "decoder.block.19.layer.2.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.4080, device='cuda:0')\n",
      "decoder.block.19.layer.2.layer_norm.weight : tensor(0.6858, device='cuda:0') tensor(0.0954, device='cuda:0')\n",
      "decoder.block.20.layer.0.SelfAttention.q.weight : tensor(5.2133e-06, device='cuda:0') tensor(0.0377, device='cuda:0')\n",
      "decoder.block.20.layer.0.SelfAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.3155, device='cuda:0')\n",
      "decoder.block.20.layer.0.SelfAttention.v.weight : tensor(-0.0002, device='cuda:0') tensor(0.5046, device='cuda:0')\n",
      "decoder.block.20.layer.0.SelfAttention.o.weight : tensor(-0.0006, device='cuda:0') tensor(0.5393, device='cuda:0')\n",
      "decoder.block.20.layer.0.layer_norm.weight : tensor(0.7733, device='cuda:0') tensor(0.2686, device='cuda:0')\n",
      "decoder.block.20.layer.1.EncDecAttention.q.weight : tensor(4.5341e-05, device='cuda:0') tensor(0.0502, device='cuda:0')\n",
      "decoder.block.20.layer.1.EncDecAttention.k.weight : tensor(0.0003, device='cuda:0') tensor(0.3968, device='cuda:0')\n",
      "decoder.block.20.layer.1.EncDecAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.7105, device='cuda:0')\n",
      "decoder.block.20.layer.1.EncDecAttention.o.weight : tensor(-0.0002, device='cuda:0') tensor(0.7010, device='cuda:0')\n",
      "decoder.block.20.layer.1.layer_norm.weight : tensor(0.4336, device='cuda:0') tensor(0.2950, device='cuda:0')\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0014, device='cuda:0') tensor(0.2662, device='cuda:0')\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0006, device='cuda:0') tensor(0.7881, device='cuda:0')\n",
      "decoder.block.20.layer.2.DenseReluDense.wo.weight : tensor(-0.0002, device='cuda:0') tensor(0.4082, device='cuda:0')\n",
      "decoder.block.20.layer.2.layer_norm.weight : tensor(0.7134, device='cuda:0') tensor(0.0947, device='cuda:0')\n",
      "decoder.block.21.layer.0.SelfAttention.q.weight : tensor(0.0001, device='cuda:0') tensor(0.0398, device='cuda:0')\n",
      "decoder.block.21.layer.0.SelfAttention.k.weight : tensor(0.0001, device='cuda:0') tensor(0.3118, device='cuda:0')\n",
      "decoder.block.21.layer.0.SelfAttention.v.weight : tensor(0.0005, device='cuda:0') tensor(0.5656, device='cuda:0')\n",
      "decoder.block.21.layer.0.SelfAttention.o.weight : tensor(5.7454e-05, device='cuda:0') tensor(0.5470, device='cuda:0')\n",
      "decoder.block.21.layer.0.layer_norm.weight : tensor(0.7860, device='cuda:0') tensor(0.2505, device='cuda:0')\n",
      "decoder.block.21.layer.1.EncDecAttention.q.weight : tensor(5.4788e-05, device='cuda:0') tensor(0.0459, device='cuda:0')\n",
      "decoder.block.21.layer.1.EncDecAttention.k.weight : tensor(0.0004, device='cuda:0') tensor(0.3863, device='cuda:0')\n",
      "decoder.block.21.layer.1.EncDecAttention.v.weight : tensor(0.0010, device='cuda:0') tensor(0.7906, device='cuda:0')\n",
      "decoder.block.21.layer.1.EncDecAttention.o.weight : tensor(0.0008, device='cuda:0') tensor(0.7338, device='cuda:0')\n",
      "decoder.block.21.layer.1.layer_norm.weight : tensor(0.4933, device='cuda:0') tensor(0.3244, device='cuda:0')\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_0.weight : tensor(-0.0003, device='cuda:0') tensor(0.2813, device='cuda:0')\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0005, device='cuda:0') tensor(0.9592, device='cuda:0')\n",
      "decoder.block.21.layer.2.DenseReluDense.wo.weight : tensor(-0.0003, device='cuda:0') tensor(0.4156, device='cuda:0')\n",
      "decoder.block.21.layer.2.layer_norm.weight : tensor(0.6664, device='cuda:0') tensor(0.1007, device='cuda:0')\n",
      "decoder.block.22.layer.0.SelfAttention.q.weight : tensor(1.7616e-05, device='cuda:0') tensor(0.0360, device='cuda:0')\n",
      "decoder.block.22.layer.0.SelfAttention.k.weight : tensor(0.0005, device='cuda:0') tensor(0.3222, device='cuda:0')\n",
      "decoder.block.22.layer.0.SelfAttention.v.weight : tensor(-0.0005, device='cuda:0') tensor(0.4747, device='cuda:0')\n",
      "decoder.block.22.layer.0.SelfAttention.o.weight : tensor(0.0004, device='cuda:0') tensor(0.5088, device='cuda:0')\n",
      "decoder.block.22.layer.0.layer_norm.weight : tensor(0.8111, device='cuda:0') tensor(0.2968, device='cuda:0')\n",
      "decoder.block.22.layer.1.EncDecAttention.q.weight : tensor(3.4193e-05, device='cuda:0') tensor(0.0447, device='cuda:0')\n",
      "decoder.block.22.layer.1.EncDecAttention.k.weight : tensor(0.0002, device='cuda:0') tensor(0.3821, device='cuda:0')\n",
      "decoder.block.22.layer.1.EncDecAttention.v.weight : tensor(0.0004, device='cuda:0') tensor(0.8018, device='cuda:0')\n",
      "decoder.block.22.layer.1.EncDecAttention.o.weight : tensor(-0.0012, device='cuda:0') tensor(0.7086, device='cuda:0')\n",
      "decoder.block.22.layer.1.layer_norm.weight : tensor(0.5153, device='cuda:0') tensor(0.3655, device='cuda:0')\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_0.weight : tensor(0.0018, device='cuda:0') tensor(0.3111, device='cuda:0')\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_1.weight : tensor(1.7211e-05, device='cuda:0') tensor(1.0081, device='cuda:0')\n",
      "decoder.block.22.layer.2.DenseReluDense.wo.weight : tensor(-0.0007, device='cuda:0') tensor(0.4340, device='cuda:0')\n",
      "decoder.block.22.layer.2.layer_norm.weight : tensor(0.6234, device='cuda:0') tensor(0.1240, device='cuda:0')\n",
      "decoder.block.23.layer.0.SelfAttention.q.weight : tensor(5.5602e-05, device='cuda:0') tensor(0.0366, device='cuda:0')\n",
      "decoder.block.23.layer.0.SelfAttention.k.weight : tensor(-4.9806e-05, device='cuda:0') tensor(0.3191, device='cuda:0')\n",
      "decoder.block.23.layer.0.SelfAttention.v.weight : tensor(4.0535e-05, device='cuda:0') tensor(0.5083, device='cuda:0')\n",
      "decoder.block.23.layer.0.SelfAttention.o.weight : tensor(0.0006, device='cuda:0') tensor(0.5271, device='cuda:0')\n",
      "decoder.block.23.layer.0.layer_norm.weight : tensor(0.7454, device='cuda:0') tensor(0.3312, device='cuda:0')\n",
      "decoder.block.23.layer.1.EncDecAttention.q.weight : tensor(-8.6648e-06, device='cuda:0') tensor(0.0440, device='cuda:0')\n",
      "decoder.block.23.layer.1.EncDecAttention.k.weight : tensor(-0.0005, device='cuda:0') tensor(0.3552, device='cuda:0')\n",
      "decoder.block.23.layer.1.EncDecAttention.v.weight : tensor(0.0006, device='cuda:0') tensor(1.0050, device='cuda:0')\n",
      "decoder.block.23.layer.1.EncDecAttention.o.weight : tensor(-0.0003, device='cuda:0') tensor(0.8172, device='cuda:0')\n",
      "decoder.block.23.layer.1.layer_norm.weight : tensor(0.5299, device='cuda:0') tensor(0.3918, device='cuda:0')\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_0.weight : tensor(0.0034, device='cuda:0') tensor(0.3170, device='cuda:0')\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_1.weight : tensor(-0.0006, device='cuda:0') tensor(1.0843, device='cuda:0')\n",
      "decoder.block.23.layer.2.DenseReluDense.wo.weight : tensor(-0.0010, device='cuda:0') tensor(0.4591, device='cuda:0')\n",
      "decoder.block.23.layer.2.layer_norm.weight : tensor(0.6103, device='cuda:0') tensor(0.1511, device='cuda:0')\n",
      "decoder.final_layer_norm.weight : tensor(1.1791, device='cuda:0') tensor(1.3014, device='cuda:0')\n",
      "lm_head.weight : tensor(-0.0017, device='cuda:0') tensor(0.4957, device='cuda:0')\n",
      "audio_encoder.modality_a : tensor(-0.0005, device='cuda:0') tensor(0.0202, device='cuda:0')\n",
      "audio_encoder.pos_embed_a : tensor(0.4354, device='cuda:0') tensor(0.5572, device='cuda:0')\n",
      "audio_encoder.patch_embed_a.proj.weight : tensor(-5.5008e-05, device='cuda:0') tensor(0.0442, device='cuda:0')\n",
      "audio_encoder.patch_embed_a.proj.bias : tensor(-1.4981e+16, device='cuda:0') tensor(4.1516e+17, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1.weight : tensor(1., device='cuda:0') tensor(3.2812e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1.bias : tensor(1.7202e-08, device='cuda:0') tensor(3.2861e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.attn.qkv.weight : tensor(-1.7845e-06, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.attn.qkv.bias : tensor(5.9930e-08, device='cuda:0') tensor(1.8576e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.attn.proj.weight : tensor(3.0577e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.attn.proj.bias : tensor(1.1196e-07, device='cuda:0') tensor(3.4525e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.4037e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2.bias : tensor(1.1263e-07, device='cuda:0') tensor(3.3806e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.0.mlp.fc1.weight : tensor(3.5305e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.mlp.fc1.bias : tensor(-2.2959e-08, device='cuda:0') tensor(3.2034e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.mlp.fc2.weight : tensor(-2.9291e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.0.mlp.fc2.bias : tensor(1.7513e-08, device='cuda:0') tensor(3.3089e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.3100e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1.bias : tensor(7.9218e-08, device='cuda:0') tensor(3.2946e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.attn.qkv.weight : tensor(8.0734e-06, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.attn.qkv.bias : tensor(-3.5654e-08, device='cuda:0') tensor(1.9643e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.attn.proj.weight : tensor(-4.5539e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.attn.proj.bias : tensor(6.9511e-09, device='cuda:0') tensor(3.4463e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.5956e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2.bias : tensor(-1.3673e-08, device='cuda:0') tensor(3.4758e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.1.mlp.fc1.weight : tensor(-1.5028e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.mlp.fc1.bias : tensor(1.8410e-08, device='cuda:0') tensor(3.0317e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.mlp.fc2.weight : tensor(-3.9450e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.1.mlp.fc2.bias : tensor(-7.2719e-08, device='cuda:0') tensor(2.8042e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1.weight : tensor(1.0000, device='cuda:0') tensor(2.8083e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1.bias : tensor(-8.8642e-08, device='cuda:0') tensor(2.7490e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.attn.qkv.weight : tensor(-1.3242e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.attn.qkv.bias : tensor(2.1646e-08, device='cuda:0') tensor(1.7518e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.attn.proj.weight : tensor(6.2276e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.attn.proj.bias : tensor(1.0691e-07, device='cuda:0') tensor(3.0257e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.2985e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2.bias : tensor(1.1590e-07, device='cuda:0') tensor(3.1513e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.2.mlp.fc1.weight : tensor(5.7054e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.mlp.fc1.bias : tensor(-4.8403e-08, device='cuda:0') tensor(3.3808e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.mlp.fc2.weight : tensor(2.4441e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.2.mlp.fc2.bias : tensor(6.4776e-09, device='cuda:0') tensor(3.1312e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.5219e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1.bias : tensor(-4.6701e-08, device='cuda:0') tensor(3.3353e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.attn.qkv.weight : tensor(4.6253e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.attn.qkv.bias : tensor(6.1501e-08, device='cuda:0') tensor(2.0057e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.attn.proj.weight : tensor(7.5942e-05, device='cuda:0') tensor(0.0360, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.attn.proj.bias : tensor(1.6773e-08, device='cuda:0') tensor(3.0629e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.4237e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2.bias : tensor(-1.9253e-08, device='cuda:0') tensor(3.1711e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.3.mlp.fc1.weight : tensor(1.5825e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.mlp.fc1.bias : tensor(-9.7053e-08, device='cuda:0') tensor(3.1883e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.mlp.fc2.weight : tensor(-2.1129e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.3.mlp.fc2.bias : tensor(8.3162e-08, device='cuda:0') tensor(3.7306e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.5261e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1.bias : tensor(9.6627e-08, device='cuda:0') tensor(3.4012e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.attn.qkv.weight : tensor(-2.2417e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.attn.qkv.bias : tensor(1.2542e-08, device='cuda:0') tensor(1.7143e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.attn.proj.weight : tensor(-1.7902e-06, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.attn.proj.bias : tensor(1.0110e-07, device='cuda:0') tensor(3.4288e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.5077e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2.bias : tensor(1.6546e-08, device='cuda:0') tensor(3.2719e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.4.mlp.fc1.weight : tensor(1.4856e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.mlp.fc1.bias : tensor(-1.8881e-08, device='cuda:0') tensor(3.2122e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.mlp.fc2.weight : tensor(-1.0288e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.4.mlp.fc2.bias : tensor(9.6878e-08, device='cuda:0') tensor(3.1712e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.4264e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1.bias : tensor(1.2255e-07, device='cuda:0') tensor(3.1017e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.attn.qkv.weight : tensor(3.2239e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.attn.qkv.bias : tensor(1.4650e-08, device='cuda:0') tensor(1.7335e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.attn.proj.weight : tensor(1.9528e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.attn.proj.bias : tensor(6.0629e-08, device='cuda:0') tensor(2.8879e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.1514e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2.bias : tensor(1.5256e-07, device='cuda:0') tensor(2.9785e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.5.mlp.fc1.weight : tensor(5.9531e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.mlp.fc1.bias : tensor(-5.0286e-08, device='cuda:0') tensor(3.3994e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.mlp.fc2.weight : tensor(8.2602e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.5.mlp.fc2.bias : tensor(1.2019e-07, device='cuda:0') tensor(2.8894e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.3701e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1.bias : tensor(1.1735e-07, device='cuda:0') tensor(2.9244e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.attn.qkv.weight : tensor(7.0200e-06, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.attn.qkv.bias : tensor(2.9358e-08, device='cuda:0') tensor(1.9093e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.attn.proj.weight : tensor(2.4967e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.attn.proj.bias : tensor(3.6845e-08, device='cuda:0') tensor(2.9078e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.2050e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2.bias : tensor(-5.3883e-09, device='cuda:0') tensor(2.7648e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.6.mlp.fc1.weight : tensor(1.1125e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.mlp.fc1.bias : tensor(4.0205e-08, device='cuda:0') tensor(3.3425e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.mlp.fc2.weight : tensor(-7.4065e-07, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.6.mlp.fc2.bias : tensor(-1.4473e-07, device='cuda:0') tensor(3.5023e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1.weight : tensor(1., device='cuda:0') tensor(3.8008e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1.bias : tensor(-1.5396e-07, device='cuda:0') tensor(3.4989e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.attn.qkv.weight : tensor(4.3986e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.attn.qkv.bias : tensor(-4.1048e-08, device='cuda:0') tensor(1.7726e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.attn.proj.weight : tensor(-2.9008e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.attn.proj.bias : tensor(1.7718e-09, device='cuda:0') tensor(2.8487e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.4356e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2.bias : tensor(-4.1006e-08, device='cuda:0') tensor(2.9366e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.7.mlp.fc1.weight : tensor(-5.8810e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.mlp.fc1.bias : tensor(-5.8391e-08, device='cuda:0') tensor(3.2651e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.mlp.fc2.weight : tensor(-9.4914e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.7.mlp.fc2.bias : tensor(3.3467e-08, device='cuda:0') tensor(3.2532e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1.weight : tensor(1., device='cuda:0') tensor(3.9094e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1.bias : tensor(2.6028e-08, device='cuda:0') tensor(3.2928e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.attn.qkv.weight : tensor(3.8639e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.attn.qkv.bias : tensor(1.4247e-08, device='cuda:0') tensor(1.8403e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.attn.proj.weight : tensor(2.7476e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.attn.proj.bias : tensor(-7.4734e-08, device='cuda:0') tensor(3.0139e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.7360e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2.bias : tensor(-6.2776e-08, device='cuda:0') tensor(3.0567e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.8.mlp.fc1.weight : tensor(-3.6755e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.mlp.fc1.bias : tensor(2.3694e-08, device='cuda:0') tensor(3.2842e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.mlp.fc2.weight : tensor(-1.4377e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.8.mlp.fc2.bias : tensor(-6.8777e-08, device='cuda:0') tensor(3.3306e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1.weight : tensor(1.0000, device='cuda:0') tensor(3.9059e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1.bias : tensor(-1.0592e-07, device='cuda:0') tensor(3.3879e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.attn.qkv.weight : tensor(2.3028e-06, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.attn.qkv.bias : tensor(2.6465e-08, device='cuda:0') tensor(1.6278e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.attn.proj.weight : tensor(2.8576e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.attn.proj.bias : tensor(-2.3744e-08, device='cuda:0') tensor(3.3356e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2.weight : tensor(1., device='cuda:0') tensor(4.0228e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2.bias : tensor(2.6749e-09, device='cuda:0') tensor(3.3669e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.9.mlp.fc1.weight : tensor(1.2094e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.mlp.fc1.bias : tensor(-1.1418e-08, device='cuda:0') tensor(3.3297e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.mlp.fc2.weight : tensor(-1.9648e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.9.mlp.fc2.bias : tensor(2.0069e-07, device='cuda:0') tensor(3.5854e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1.weight : tensor(1.0000, device='cuda:0') tensor(4.3561e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1.bias : tensor(2.4553e-07, device='cuda:0') tensor(3.5484e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.attn.qkv.weight : tensor(1.0618e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.attn.qkv.bias : tensor(7.7569e-08, device='cuda:0') tensor(1.7079e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.attn.proj.weight : tensor(-8.6677e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.attn.proj.bias : tensor(-2.2925e-08, device='cuda:0') tensor(3.2214e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2.weight : tensor(1.0000, device='cuda:0') tensor(3.9062e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2.bias : tensor(-4.4889e-08, device='cuda:0') tensor(3.0555e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2_a.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2_a.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_a.10.mlp.fc1.weight : tensor(-8.0386e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.mlp.fc1.bias : tensor(2.2727e-09, device='cuda:0') tensor(3.4301e-06, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.mlp.fc2.weight : tensor(-1.5492e-05, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_a.10.mlp.fc2.bias : tensor(-1.1647e-07, device='cuda:0') tensor(2.9821e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1_a.weight : tensor(1.0000, device='cuda:0') tensor(3.8758e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1_a.bias : tensor(-1.6365e-07, device='cuda:0') tensor(3.0130e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm1_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.attn.qkv.weight : tensor(2.1287e-05, device='cuda:0') tensor(0.0255, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.attn.qkv.bias : tensor(-3.3739e-09, device='cuda:0') tensor(1.4692e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.attn.proj.weight : tensor(6.0550e-06, device='cuda:0') tensor(0.0361, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.attn.proj.bias : tensor(-2.0618e-07, device='cuda:0') tensor(3.6600e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2_a.weight : tensor(1.0000, device='cuda:0') tensor(4.4440e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2_a.bias : tensor(-1.6302e-07, device='cuda:0') tensor(3.6175e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2_v.weight : tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.norm2_v.bias : tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "audio_encoder.blocks_u.0.mlp.fc1.weight : tensor(-7.2464e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.mlp.fc1.bias : tensor(5.8178e-09, device='cuda:0') tensor(2.9054e-06, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.mlp.fc2.weight : tensor(-6.4172e-06, device='cuda:0') tensor(0.0228, device='cuda:0')\n",
      "audio_encoder.blocks_u.0.mlp.fc2.bias : tensor(-9.6445e-07, device='cuda:0') tensor(5.8007e-06, device='cuda:0')\n",
      "audio_encoder.norm_a.weight : tensor(1.0000, device='cuda:0') tensor(4.4529e-06, device='cuda:0')\n",
      "audio_encoder.norm_a.bias : tensor(-9.8496e-07, device='cuda:0') tensor(5.6700e-06, device='cuda:0')\n",
      "audio_proj.1.weight : tensor(-1.4630e+13, device='cuda:0') tensor(1.2974e+16, device='cuda:0')\n",
      "audio_proj.1.bias : tensor(-1.1236e+16, device='cuda:0') tensor(3.5954e+17, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Model parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, \":\", param.data.mean(), param.data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6669f4d-2425-4258-b079-eb694655e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 30207: ['zugreifen']\n"
     ]
    }
   ],
   "source": [
    "print(\"Token 30207:\", tokenizer.convert_ids_to_tokens([30207]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014ed27-f182-4946-b8cf-74a71f96de60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225acc9-ea9c-4665-a7fa-5891338c9b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3b903-748b-4cfb-851c-bacff8a599bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56207f0-2a07-4b0a-8973-76d3f6490f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db39cfaa-5833-4bea-8b7d-242fddd2ff65",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61e18f-41af-4dcd-8fed-676f33666e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"working_model_2.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10efe568-3e31-4845-af27-f422fd7e0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cave_model import CAVMAEFTAudio\n",
    "audio_encoder = CAVMAEFTAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1a5635-50ab-4e71-8fb5-4b2c1355ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from CAVE inside: tensor([[[-2.2843, -2.4218, -2.0455,  ..., -0.9920, -1.5722, -2.3284],\n",
      "         [-1.8898, -2.3895, -1.6217,  ..., -0.2275, -1.0407, -2.1476],\n",
      "         [-1.6393, -2.1380, -1.3702,  ...,  0.0030, -0.7107, -1.5814],\n",
      "         ...,\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329],\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329],\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329]]])\n",
      "shape before CAVE: torch.Size([1, 1024, 128])\n",
      "from CAVE before patch: tensor([[[[-2.2843, -1.8898, -1.6393,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.4218, -2.3895, -2.1380,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.0455, -1.6217, -1.3702,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          ...,\n",
      "          [-0.9920, -0.2275,  0.0030,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-1.5722, -1.0407, -0.7107,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.3284, -2.1476, -1.5814,  ...,  1.1329,  1.1329,  1.1329]]]])\n",
      "patch embed: torch.Size([1, 1, 128, 1024])\n",
      "before convo: tensor([[[[-2.2843, -1.8898, -1.6393,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.4218, -2.3895, -2.1380,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.0455, -1.6217, -1.3702,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          ...,\n",
      "          [-0.9920, -0.2275,  0.0030,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-1.5722, -1.0407, -0.7107,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.3284, -2.1476, -1.5814,  ...,  1.1329,  1.1329,  1.1329]]]])\n",
      "from CAVE after patch: tensor([[[ 2.6611, -1.2217, -0.2890,  ..., -0.4917, -0.9088,  0.5112],\n",
      "         [ 2.8197, -1.7707, -0.3036,  ..., -0.0717, -1.1140,  0.7702],\n",
      "         [ 3.2779, -2.0465, -0.2818,  ..., -0.2168, -1.5610,  1.0363],\n",
      "         ...,\n",
      "         [-1.7904,  1.0632,  0.1043,  ...,  0.2845,  0.6632, -0.7552],\n",
      "         [-1.7904,  1.0632,  0.1043,  ...,  0.2845,  0.6632, -0.7552],\n",
      "         [-1.7904,  1.0632,  0.1043,  ...,  0.2845,  0.6632, -0.7552]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "from CAVE inside 2: tensor([[[ 2.6773, -1.2612, -0.2841,  ...,  0.4644,  0.1219,  1.4585],\n",
      "         [ 3.6774, -0.9949,  0.4899,  ...,  0.8844, -0.0833,  1.7175],\n",
      "         [ 4.2034, -1.1418,  0.6930,  ...,  0.7394, -0.5303,  1.9836],\n",
      "         ...,\n",
      "         [-2.7403,  2.0234, -0.7949,  ...,  1.2407,  1.6939,  0.1920],\n",
      "         [-2.5134,  1.5836, -0.1096,  ...,  1.2407,  1.6939,  0.1920],\n",
      "         [-1.6068,  0.6724,  0.7441,  ...,  1.2407,  1.6939,  0.1920]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "shape before putting in block: torch.Size([1, 512, 768])\n",
      "from CAVE inside 3: tensor([[[-1.9227, -0.8392, -0.0687,  ..., -0.0199, -0.1403, -0.5158],\n",
      "         [-1.8927, -0.8580, -0.0356,  ...,  0.0313, -0.1316, -0.5077],\n",
      "         [-1.8534, -0.8358,  0.0105,  ...,  0.0134, -0.0942, -0.5143],\n",
      "         ...,\n",
      "         [-2.3141, -0.5856, -0.3207,  ..., -0.3211,  0.0934, -0.4715],\n",
      "         [-2.3242, -0.6239, -0.3015,  ..., -0.2697,  0.0892, -0.4805],\n",
      "         [-2.3116, -0.6845, -0.2764,  ..., -0.2048,  0.0723, -0.4951]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "from CAVE inside 4: tensor([[[-1.7023, -0.7344, -0.0461,  ..., -0.0025, -0.1100, -0.4455],\n",
      "         [-1.6768, -0.7517, -0.0163,  ...,  0.0435, -0.1022, -0.4384],\n",
      "         [-1.6403, -0.7311,  0.0251,  ...,  0.0277, -0.0684, -0.4439],\n",
      "         ...,\n",
      "         [-2.0549, -0.5034, -0.2656,  ..., -0.2660,  0.1061, -0.4010],\n",
      "         [-2.0651, -0.5383, -0.2489,  ..., -0.2203,  0.1020, -0.4096],\n",
      "         [-2.0548, -0.5933, -0.2267,  ..., -0.1624,  0.0865, -0.4231]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7023, -0.7344, -0.0461,  ..., -0.0025, -0.1100, -0.4455],\n",
       "         [-1.6768, -0.7517, -0.0163,  ...,  0.0435, -0.1022, -0.4384],\n",
       "         [-1.6403, -0.7311,  0.0251,  ...,  0.0277, -0.0684, -0.4439],\n",
       "         ...,\n",
       "         [-2.0549, -0.5034, -0.2656,  ..., -0.2660,  0.1061, -0.4010],\n",
       "         [-2.0651, -0.5383, -0.2489,  ..., -0.2203,  0.1020, -0.4096],\n",
       "         [-2.0548, -0.5933, -0.2267,  ..., -0.1624,  0.0865, -0.4231]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"./data/toy_dataset/audio/577026.flac\"\n",
    "cur_audio_input, audio_info = load_audio(file)\n",
    "cur_audio_input = cur_audio_input.unsqueeze(0)\n",
    "audio_input = audio_encoder(cur_audio_input) \n",
    "audio_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4241216e-6a36-4ead-b4c7-1b3f7fc434f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from CAVE inside: tensor([[[-2.2843, -2.4218, -2.0455,  ..., -0.9920, -1.5722, -2.3284],\n",
      "         [-1.8898, -2.3895, -1.6217,  ..., -0.2275, -1.0407, -2.1476],\n",
      "         [-1.6393, -2.1380, -1.3702,  ...,  0.0030, -0.7107, -1.5814],\n",
      "         ...,\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329],\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329],\n",
      "         [ 1.1329,  1.1329,  1.1329,  ...,  1.1329,  1.1329,  1.1329]]],\n",
      "       device='cuda:0')\n",
      "shape before CAVE: torch.Size([1, 1024, 128])\n",
      "from CAVE before patch: tensor([[[[-2.2843, -1.8898, -1.6393,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.4218, -2.3895, -2.1380,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.0455, -1.6217, -1.3702,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          ...,\n",
      "          [-0.9920, -0.2275,  0.0030,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-1.5722, -1.0407, -0.7107,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.3284, -2.1476, -1.5814,  ...,  1.1329,  1.1329,  1.1329]]]],\n",
      "       device='cuda:0')\n",
      "patch embed: torch.Size([1, 1, 128, 1024])\n",
      "before convo: tensor([[[[-2.2843, -1.8898, -1.6393,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.4218, -2.3895, -2.1380,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.0455, -1.6217, -1.3702,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          ...,\n",
      "          [-0.9920, -0.2275,  0.0030,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-1.5722, -1.0407, -0.7107,  ...,  1.1329,  1.1329,  1.1329],\n",
      "          [-2.3284, -2.1476, -1.5814,  ...,  1.1329,  1.1329,  1.1329]]]],\n",
      "       device='cuda:0')\n",
      "from CAVE after patch: tensor([[[-1.9091, -0.8451,  0.2472,  ...,  0.1447, -0.0661,  0.8762],\n",
      "         [-2.0660, -1.2898,  0.4945,  ...,  0.3127, -1.1853,  1.2340],\n",
      "         [-2.3570, -1.1388,  0.7489,  ...,  0.3829, -1.1931,  0.9730],\n",
      "         ...,\n",
      "         [ 0.7995,  0.6390, -0.5792,  ..., -0.1193,  0.6473, -0.6660],\n",
      "         [ 0.7995,  0.6390, -0.5792,  ..., -0.1193,  0.6473, -0.6660],\n",
      "         [ 0.7995,  0.6390, -0.5792,  ..., -0.1193,  0.6473, -0.6660]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "from CAVE inside 2: tensor([[[-1.9106, -0.8678,  0.2206,  ...,  1.1831,  0.9352,  1.8581],\n",
      "         [-1.2259, -0.4973,  1.2565,  ...,  1.3511, -0.1839,  2.2159],\n",
      "         [-1.4492, -0.2173,  1.6922,  ...,  1.4213, -0.1917,  1.9549],\n",
      "         ...,\n",
      "         [-0.1680,  1.6160, -1.5098,  ...,  0.9191,  1.6487,  0.3159],\n",
      "         [ 0.0589,  1.1762, -0.8246,  ...,  0.9191,  1.6487,  0.3159],\n",
      "         [ 0.9654,  0.2650,  0.0291,  ...,  0.9191,  1.6487,  0.3159]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "shape before putting in block: torch.Size([1, 512, 768])\n",
      "from CAVE inside 3: tensor([[[ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262],\n",
      "         [ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262],\n",
      "         [ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262],\n",
      "         ...,\n",
      "         [ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262],\n",
      "         [ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262],\n",
      "         [ 1.0819,  0.4062, -0.0914,  ...,  1.1714, -1.0042, -0.5262]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "from CAVE inside 4: tensor([[[ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739],\n",
      "         [ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739],\n",
      "         [ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739],\n",
      "         ...,\n",
      "         [ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739],\n",
      "         [ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739],\n",
      "         [ 0.9977,  0.3794, -0.0761,  ...,  1.0796, -0.9114, -0.4739]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "Audio: tensor([[[5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41],\n",
      "         [5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41],\n",
      "         [5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41],\n",
      "         ...,\n",
      "         [5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41],\n",
      "         [5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41],\n",
      "         [5.2466e+15, 1.3509e-35, 8.6795e-37,  ..., 4.0729e-41,\n",
      "          6.0559e-37, 4.0729e-41]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "input_embeds: tensor([[[ 7.5833, -5.9968, -8.7719,  ..., -1.7548, -1.4999,  0.8449],\n",
      "         [ 8.0296,  3.5735, -0.2749,  ..., -0.3696,  0.0123, -2.4261],\n",
      "         [-7.9453, -3.8064,  5.7910,  ...,  2.7917,  1.0186,  1.6824],\n",
      "         ...,\n",
      "         [-7.1989, -7.0903, 10.7553,  ...,  7.1836,  5.0034, -9.7338],\n",
      "         [ 1.5147,  3.0822, -0.0883,  ...,  0.4944,  3.2871, -6.7017],\n",
      "         [-2.7021, -2.1235,  0.5805,  ..., -2.3538, -4.8025, -5.8202]]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
      "concat shape: torch.Size([1, 43, 1024])\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/toy_dataset/audio/577026.flac\"\n",
    "cur_audio_input, audio_info = load_audio(file)\n",
    "cur_audio_input = cur_audio_input.unsqueeze(0).to(device)\n",
    "prompt_text = \"what can be infered from this audio following\"\n",
    "input_ids = tokenizer(prompt_text, return_tensors='pt').input_ids.to(device)\n",
    "target_text = \"It can be inferred that the audio is a recording of a musical performance or a rehearsal.The combination of music, speech,\"\\\n",
    "\"and sound effects suggests that the audio is a representation of a musical performance or a rehearsal, where the music is being played\"\\\n",
    "\"and the performers are practicing their performance or rehearsing.\"\n",
    "target_ids = tokenizer(target_text, return_tensors='pt').input_ids.to(device)\n",
    "decoder_input_ids = model._shift_right(target_ids).to(device)\n",
    "\n",
    "outputs = model(input_ids=input_ids, audio_input=cur_audio_input,labels=decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "657ae9e4-a045-46be-9513-55aa19c489ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/toy_dataset/audio/3CHor3uzS00.flac\"\n",
    "cur_audio_input, audio_info = load_audio(file)\n",
    "cur_audio_input = cur_audio_input.unsqueeze(0).to(device)\n",
    "prompt_text = \"what can be infered from this audio following\"\n",
    "input_ids = tokenizer(prompt_text, return_tensors='pt').input_ids.to(device)\n",
    "target_text = \"\"\n",
    "target_ids = tokenizer(target_text, return_tensors='pt').input_ids.to(device)\n",
    "decoder_input_ids = model._shift_right(target_ids).to(device)\n",
    "\n",
    "outputs = model(input_ids=input_ids, audio_input=cur_audio_input,labels=decoder_input_ids)\n",
    "logits = outputs.logits  \n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "decoded_text = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429a4ed-867c-4a2c-8cb3-22beb5a44985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "audio_encoder = CAVMAEFTAudio()\n",
    "prompt_text = \"what can be infered from this audio following\"\n",
    "input_ids = tokenizer(prompt_text, return_tensors='pt').input_ids.to(device)\n",
    "audio_input = return_audio(\"./data/toy_dataset/audio/_4X8RNeWeDI.flac\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    prompt_embeddings = model.shared(input_ids)  # Shape: (1, sequence_length, 1024)\n",
    "    prompt_embeddings = prompt_embeddings.to(device)\n",
    "\n",
    "\n",
    "target_text = \"It can be inferred that the audio is a recording of a musical performance or a rehearsal.The combination of music, speech,\"\\\n",
    "\"and sound effects suggests that the audio is a representation of a musical performance or a rehearsal, where the music is being played\"\\\n",
    "\"and the performers are practicing their performance or rehearsing.\"\n",
    "\n",
    "target_ids = tokenizer(target_text, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "decoder_input_ids = model._shift_right(target_ids)\n",
    "\n",
    "audio_embeddings = audio_input.to(device)  # Shape: (1, 32, 1024)\n",
    "\n",
    "# Concatenate prompt and audio embeddings\n",
    "combined_embeddings = torch.cat((prompt_embeddings, audio_embeddings), dim=1)  # Shape: (1, sequence_length + 32, 1024)\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "\n",
    "if combined_embeddings.size(1) > max_length:\n",
    "    combined_embeddings = combined_embeddings[:, :max_length, :]\n",
    "\n",
    "padding_length = max_length - combined_embeddings.size(1)\n",
    "if padding_length > 0:\n",
    "    padding_tensor = torch.zeros((combined_embeddings.size(0), padding_length, combined_embeddings.size(2))).to(device)\n",
    "    combined_embeddings = torch.cat((combined_embeddings, padding_tensor), dim=1)\n",
    "\n",
    "\n",
    "attention_mask = torch.ones(combined_embeddings.size(0), combined_embeddings.size(1)).to(device)\n",
    "if padding_length > 0:\n",
    "    attention_mask[:, -padding_length:] = 0\n",
    "\n",
    "\n",
    "outputs = model.generate(inputs_embeds=combined_embeddings, attention_mask=attention_mask,labels=decoder_input_ids)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bfc9b-d511-404c-a4a3-3170a3991509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
